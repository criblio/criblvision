<dashboard version="1.1">
   <label>Known Issues</label>
   <description>Last Update on July 17, 2023</description>
   <row>
      <panel>
         <html>
            <div>
               <p>This page lists known issues affecting Cribl Stream and/or CriblEdge.</p>
               <p>Check out our <a href="https://docs.cribl.io/stream/known-issues/" target="_blank">Documentation</a> for more information</p>
               <hr />
               <h3>
                  2023-07-13 - v.4.0.0-4.1.3 - When configuring an S3 Collector, JavaScript expressions break the "Auto-populate from" option for the Path field [CRIBL-18844]
               </h3>
               <p>
                  <strong>Problem</strong>:  When automatically populating an S3 Collector from an S3 Destination, the collector Path field won’t resolve JavaScript expressions, even if the expression was valid on the Destination that the field was populated from. The S3 Collector path is treated like a literal string and the software fails to warn you that the path is invalid.
               </p>
               <p>
                  <strong>Workaround</strong>: None.
               </p>
               <p>
                  <strong>Fix</strong>: Planned for Cribl Stream 4.2.1.
               </p>
               <p />
               <hr />
               <h3>
                  2023-07-07 - v.4.1.3 - When configuring an HTTP Source, enabling Source PQ changes the inputId in events [CRIBL-18668]
               </h3>
               <p>
                  <strong>Problem</strong>:  When Source-side Persistent Queueing is enabled on an HTTP Source, the trailing colon is dropped from __inputId. This will break Routes and filters that are based on the Input ID if it is copied from the configuration page. Live captures will also stop working until you modify them.
               </p>
               <p>
                  <strong>Workaround</strong>: None.
               </p>
               <p>
                  <strong>Fix</strong>: Planned for Cribl Stream 4.2.1.
               </p>
               <p />
               <hr />
               <h3>
                  2023-06-29 - All Versions through Current - (Linux) System Metrics Source does not emit "Per interface" metrics in "All" mode [CRIBL-18473]
               </h3>
               <p>
                  <strong>Problem</strong>: In the (Linux) System Metrics Source > Host Metrics tab, selecting All does not emit Per Interface metrics.
               </p>
               <p>
                  <strong>Workaround</strong>: In the Host Metrics tab, select Custom > Network > Custom then toggle Per interface metrics to Yes.
               </p>
               <p>
                  <strong>Fix</strong>: Planned for Cribl Stream 4.2.
               </p>
               <p />
               <hr />
               <h3>
                  2023-06-26 - All Versions through Current - High CPU usage in File Monitor Source's Manual mode [CRIBL-18400]
               </h3>
               <p>
                  <strong>Problem</strong>: In the File Monitor Source and the Explore > Files tab UI, the Manual mode does not honor the Max depth setting. Because the log discovery logic, used in the File Monitor Source and Files tab, recurses in the directory tree, the API process consumes high CPU resources.
               </p>
               <p>
                  <strong>Workaround</strong>: The Edge Nodes and Workers must connect to the leader using the host/port/tls connection details. If this is not possible, upgrade Edge Nodes separately using the boostrap script.
               </p>
               <p>
                  <strong>Fix</strong>: Planned for Cribl Stream 4.2.
               </p>
               <p />
               <hr />
               <h3>
                  2023-06-26 - All Versions through Current - Fleet Upgrade Errors [CRIBL-18374]
               </h3>
               <p>
                  <strong>Problem</strong>: A Fleet's upgrade from a Leader can result in errors when the Edge Nodes use different host/port/tls settings than Worker Nodes.
               </p>
               <p>
                  <strong>Workaround</strong>: The Edge Nodes and Workers must connect to the leader using the host/port/tls connection details. If this is not possible, upgrade Edge Nodes separately using the boostrap script.
               </p>
               <p>
                  <strong>Fix</strong>: TBD.
               </p>
               <p />
               <hr />
               <h3>
                  2023-06-21 - v.3.5.2-v.4.1.3 - Using the Rename Function gives unexpected results due to skipped internal fields [CRIBL-18285]
               </h3>
               <p>
                  <strong>Problem</strong>: When internal fields are present in the Rename fields list, the Rename Function may incorrectly assign field keys or values.
               </p>
               <p>
                  <strong>Workaround</strong>: This function is not intended to operate on internal fields. Avoid this operation.
               </p>
               <p>
                  <strong>Fix</strong>: Planned for Cribl Stream 4.2.
               </p>
               <p />
               <hr />
               <h3>
                  2023-06-15 - v.4.1.3 - Amazon CloudWatch Destinations log error while flushing events older than 24 hours [CRIBL-18184]
               </h3>
               <p>
                  <strong>Problem</strong>: Amazon CloudWatch Destination buffers retain events older than 24 hours, causing these Destinations to send events in batches exceeding 24 hours.
               </p>
               <p>
                  <strong>Workaround</strong>: Add a Post-Processing Pipeline with a Drop Function using a Filter Expression of _time&lt;(Date.now() / 1000) - 86400.
               </p>
               <p>
                  <strong>Fix</strong>: Planned for Cribl Stream 4.2.
               </p>
               <p />
               <hr />
               <h3>
                  2023-06-14 - v.4.1.2-4.1.3 - The Office 365 Activity Source misses events [CRIBL-18164]
               </h3>
               <p>
                  <strong>Problem</strong>: The Office 365 Activity Source misses events due to the current collection system. For services such as Exchange, SharePoint, OneDrive, and Teams, Microsoft indicates that audit record availability is typically 60 to 90 minutes after an event occurs. Our current collector methodology does not account for this availability window. Instead, the Source completes runs as scheduled and collects only events it finds during the configured time range, which can lead to missed events.
               </p>
               <p>
                  <strong>Workaround</strong>: None.
               </p>
               <p>
                  <strong>Fix</strong>: Planned for Cribl Stream 4.2.
               </p>
               <p />
               <hr />
               <h3>
                  2023-06-08 - v.4.1.2 - AES-256-GCM security vulnerability [CRIBL-18038]
               </h3>
               <p>
                  <strong>Problem</strong>: The AES-256-GCM encryption option introduced in v.4.1.2 included a security vulnerability.
               </p>
               <p>
                  <strong>Workaround</strong>: Do not use this option in v.4.1.2.
               </p>
               <p>
                  <strong>Fix</strong>: In Cribl Stream 4.1.3.
               </p>
               <p />
               <hr />
               <h3>
                  2023-06-01 - v.4.0.0-4.1.2 - GroupEdit is not able to commit changes [CRIBL-17939]
               </h3>
               <p>
                  <strong>Problem</strong>: Users having the GroupEdit policy are able to make changes (e.g. create new Sources) but are unable to Commit their changes. These users should be able to Commit, but not Deploy, changes.
               </p>
               <p>
                  <strong>Workaround</strong>: Apply the GroupFull policy for users that need to be able to Commit changes. These users will also have the ability to deploy a Worker Group or Fleet.
               </p>
               <p>
                  <strong>Fix</strong>: Planned for Cribl Stream 4.2.
               </p>
               <p />
               <hr />
               <h3>
                  2023-05-27 - v.4.1.1-4.1.2 - Perf bug: RPC consuming excessive CPU compiling expressions [CRIBL-17779]
               </h3>
               <p>
                  <strong>Problem</strong>: In 4.1.1, to improve product security, we changed how we manage our RPC traffic from Leaders and Workers. This change can have a negative impact in larger environments with many Worker Processes. Following a 4.1.1 or 4.1.2 upgrade, the Leader can become non-responsive to UI requests due to a steady 100% CPU utilization. When this happens, you cannot manage or monitor CriblStream environments.
               </p>
               <p>
                  <strong>Workaround</strong>: Roll back to a previous stable version, such as 4.1.0.
               </p>
               <p>
                  <strong>Fix</strong>: Planned for CriblStream 4.1.3.
               </p>
               <p />
               <hr />
               <h3>
                  2023-05-22 - Multiple versions through 4.1.x - Kafka-based Sources' rebalancing is logged with exaggerated severity [CRIBL-14609]
               </h3>
               <p>
                  <strong>Problem</strong>: The Kafka, Azure EventHubs, and ConfluentCloud Sources log <code>REBALANCE_IN_PROGRESS</code> events at the <code>error</code> level, even though only <strong>frequent</strong> rebalancing indicates a system-level or processing issue.
               </p>
               <p>
                  <strong>Workaround</strong>: Treat infrequent rebalancing events as <code>warn</code>.
               </p>
               <p>
                  <strong>Fix</strong>: Depends on a change to the <a href="https://github.com/tulios/kafkajs/issues/1468" target="_blank" rel="noopener noreferrer">underlying kafkajs library</a>.
               </p>
               <p />
               <hr />
               <h3>
                  2023-05-19 - v.4.1.2 - CrowdStrike Destination's "LogScaleendpoint" field hidden from UI [CRIBL-17715]
               </h3>
               <p>
                  <strong>Problem</strong>: The CrowdStrike Falcon LogScale Destination's <strong>LogScaleendpoint</strong> field is hidden from the 4.1.2 configuration modal, but can be restored.
               </p>
               <p>
                  <strong>Workaround</strong>: Follow these steps, in sequence, for each LogScale Destination.<br />
                  1.Populate the LogScale config modal, and save once.<br />
                  2.Reopen the modal, then select <strong>ManageasJSON</strong>.<br />
                  3.Change the <code>"loadbalanced":</code> key's value from <code>true</code> to <code>false</code>.<br />
                  4.Copy this default nested element:
                  <code>"url": "https://cloud.us.humio.com/api/v1/ingest/hec",</code>
                  <br />
                  5.Paste it above the whole <code>"urls"</code> element (typically at line 21).<br />
                  6.Click <strong>OK</strong> to restore the visual UI, with the <strong>LogScaleendpoint</strong> field now visible.<br />
                  7.Enter your actual endpoint URL, and save the config.
               </p>
               <p>
                  <strong>Fix</strong>: Planned for CriblStream 4.1.3.
               </p>
               <p />
               <hr />
               <h3>
                  2023-05-16 - v.4.1.1-4.1.2 - Expanding Status of Output Router Destination triggers error [CRIBL-17632]
               </h3>
               <p>
                  <strong>Problem</strong>: When you attempt to expand a node on the <strong>Status</strong> tab for an OutputRouter Destination, the page crashes and the error <code>Cannot convert undefined or null to object</code> appears. 
               </p>
               <p>
                  <strong>Fix</strong>: Planned for CriblStream 4.1.3.
               </p>
               <hr />
               <h3>
                  2023-05-12 - v.4.0-4.1.2 - The Kubernetes Logs Source drops events [CRIBL-17602]
               </h3>
               <p>
                  <strong>Problem</strong>: Events from a running container will stall when the underlying container runtime rotates the log file. Any further rotation of log files will result in data loss. 
               </p>
               <p>
                  <strong>Workaround</strong>: Restart the Kubernetes Logs Source to reconnect.
               </p>
               <p>
                  <strong>Fix</strong>: Planned for CriblStream 4.1.3.
               </p>
               <p />
               <hr />
               <h3>
                  2023-05-05 - v.4.1.1 - S3 ingestion slows after upgrade [CRIBL-17317]
               </h3>
               <p>
                  <strong>Problem</strong>: After upgrading to CriblStream 4.1.1, ingesting using any <code>JSON</code> Array Event Breaker (such as AWS CloudTrail) will slow or stop due to high CPU usage.
               </p>
               <p>
                  <strong>Workaround</strong>: Roll back to a previous stable version, such as 4.1.0.
               </p>
               <p>
                  <strong>Fix</strong>: In CriblStream 4.1.2.
               </p>
               <p />
               <hr />
               <h3>
                  2023-04-27 - v.4.1.1 - 4.1.1. WorkerNodes integrated with <code>systemd/initd</code> can fail upon reconfig [CRIBL-17264]
               </h3>
               <p>
                  <strong>Problem</strong>: Where 4.1.1 on-prem or hybrid WorkerNodes (on Linux) are integrated with <code>systemd/initd</code>, deploying new config bundles to those WorkerNodes can stop the WorkerNodes from processing data. The root cause is an incorrect backup step, which (depending on permissions) can also consume large amounts of disk space on their hosts.
               </p>
               <p>
                  <strong>Precondition:</strong> Cribl-managed Cloud instances are unaffected. This problem has been observed only if at least one of the following directories is populated, or exists with restricted permissions:
               </p>
               <pre>
<code>
<span>/data/</span>
<span>/default/cribl/</span>
<span>/default/edge/</span>
<span>/local/cribl/</span>
<span>/local/edge/</span>
<span>/default/&lt;any-installed-Pack-name&gt;/</span>
<span>/local/&lt;any-installed-Pack-name&gt;/</span>
</code>
</pre>
               <p>
                  <strong>Workaround</strong>: Skip v.4.1.1 or roll back to your last stable version. To run v.4.1.1, this workaround is available on systemd's <code>Service</code> section: 1.In the script <code>/etc/systemd/system/cribl.service</code>, add the line: <code>WorkingDirectory=/opt/cribl</code>, (This is the default path - specify your own path equivalent to <code>$CRIBL_HOME</code>). 2.Then reload the systemd daemon: <code>systemctl daemon-reload</code>. 3.Then restart the Cribl Stream instance using <code>systemctl restart &lt;service name&gt;</code>.
               </p>
               <p>
                  <strong>Fix</strong>: In CriblStream 4.1.2.
               </p>
               <p />
               <hr />
               <h3>
                  2023-04-14 - v.2.2-4.1.x - Requests from Office 365 Message Trace Source failed intermittently [CRIBL-16929]
               </h3>
               <p>
                  <strong>Problem</strong>: Microsoft has fixed this Office 365 Message Trace API problem with <a href="https://portal.office.com/adminportal/home#/servicehealth/:/alerts/EX544330" target="_blank" rel="noopener noreferrer">this patch</a> (Microsoft login required). Before this patch, requests failed intermittently, often with <code>Non-whitespace</code> errors.
               </p>
               <p>
                  <strong>Fix</strong>: Fixed by Microsoft (not a Cribl problem).
               </p>
               <p />
               <hr />
               <h3>
                  2023-04-13 - v.4.1.1 - Monitoring incorrectly shows metrics for disconnected Subscriptions [CRIBL-16926]
               </h3>
               <p>
                  <strong>Problem</strong>: Selecting <strong>Monitoring</strong> &gt; <strong>Data</strong> &gt; <strong>Subscriptions</strong> will falsely show statistics even for Subscriptions that are not connected to a Destination, and therefore have no data flow.
               </p>
               <p>
                  <strong>Workaround</strong>: Ignore these Monitoring statistics.
               </p>
               <p>
                  <strong>Fix</strong>: In CriblStream 4.1.2.
               </p>
               <p />
               <hr />
               <h3>
                  2023-04-03 - v.4.1.0 - Windows Event Logs Source should have a configurable Max Event Size [CRIBL-16549]
               </h3>
               <p>
                  <strong>Problem</strong>: Events aren't broken properly when collecting logs from the PowerShell event log. The Source contains a Max Event Limit of <code>51200</code>, which is a hard-coded breaker config. This limit should be configurable. 
               </p>
               <p>
                  <strong>Fix</strong>: In CriblStream 4.1.1.
               </p>
               <p />
               <hr />
               <h3>
                  2023-03-31 - v.4.1.0 - Cribl.Cloud API Credential's Roles aren't honored on tokens [SAAS-3681]
               </h3>
               <p>
                  <strong>Problem</strong>: API Bearer tokens obtained <a url="api-tutorials/" anchor="#criblcloud-free-tier" href="https://docs.cribl.io/stream/api-tutorials/#criblcloud-free-tier" target="_blank">through the Cribl.Cloud portal</a> are all granted the <code>Admin</code> Role, regardless of the scope specified on the parent Credential.
               </p>
               <p>
                  <strong>Workaround</strong>: Use the <a product="stream" href="https://docs.cribl.io/stream/4.0/api-tutorials#tokens" target="_blank">pre-4.0 workaround</a> to obtain Bearer tokens from the in-app API Reference.
               </p>
               <p>
                  <strong>Fix</strong>: In CriblStream 4.1.2.
               </p>
               <p />
               <hr />
               <h3>
                  2023-03-30 v.4.1.0 - Splunk Load Balanced Destination incorrectly re-creates all connections during DNS resolution [CRIBL-16494]
               </h3>
               <p>
                  <strong>Problem</strong>: When <strong>Minimize in-flight data loss</strong> is enabled, the Splunk Load Balanced Destination re-creates all outbound connections during DNS resolution. This will cause the Destination to report a blocked status until the outbound connections refresh. Ifpersistentqueues (PQ) are enabled, PQ will engage while the Destination is blocked.
               </p>
               <p>
                  <strong>Workaround</strong>: Select the Destination's <strong>Manageas JSON</strong> option, to add the key-value pair: <code>"maxFailedHealthChecks": 1</code>.
               </p>
               <p>
                  <strong>Fix</strong>: In CriblStream 4.1.1.
               </p>
               <p />
               <hr />
               <h3>
                  2023-03-28 - v.4.1.0 - Add Kubernetes and Docker modals in the UI aren't checking the <code>CRIBL_BOOTSTRAP_HOST</code> environment variable [CRIBL-16432]
               </h3>
               <p>
                  <strong>Problem</strong>: The Add Windows and Linux modals check for a bootstrap hostname to see if a user has configured a host override with the <code>CRIBL_BOOTSTRAP_HOST</code> environment variable. The Add Kubernetes and Docker modals aren't checking the environment variable as expected.
               </p>
               <p>
                  <strong>Fix</strong>: In CriblStream 4.1.1.
               </p>
               <p />
               <hr />
               <h3>
                  2023-03-23 - v.4.1.0 - Leader's config deployments to pre-4.1 Workers silently fail [CRIBL-16339]
               </h3>
               <p>
                  <strong>Problem</strong>: A 4.1.x Leader requires Workers to also be upgraded to - v.4.1.x. If you attempt to deploy configs to Workers running earlier versions, the intended upgrade prompt might not appear. In this case, the deploy will silently hang.
               </p>
               <p>
                  <strong>Workaround</strong>: If you haven't enabled automatic upgrades of on-prem or hybrid Workers, upgrade all WorkerGroups to 4.1.x before you deploy to them.
               </p>
               <p>
                  <strong>Fix</strong>: In CriblStream 4.1.1.
               </p>
               <p />
               <hr />
               <h3>
                  2023-03-22 - v.4.1.0-4.1.1 - Cribl Stream Database Collector cannot connect with SQL Server using AD authentication [CRIBL-16304]
               </h3>
               <p>
                  <strong>Problem</strong>: On the indicated versions, the Database Collector cannot connect with SQL Server using Active Directory (AD) authentication. (Only local auth works.) 
               </p>
               <p>
                  <strong>Workaround</strong>: Reverting to Cribl Stream v.4.0.4 restores the Database Collector's ability to connect using AD authentication.
               </p>
               <p>
                  <strong>Fix</strong>: In Cribl Stream 4.1.2.
               </p>
               <p />
               <hr />
               <h3>
                  2023-03-21 - v.4.1 - Unable to bind <code>CRIBL_DIST_MASTER_URL</code> to an IPv6 address [CRIBL-16284]
               </h3>
               <p>
                  <strong>Problem</strong>: Due to an issue with the <code>CRIBL_DIST_MASTER_URL</code> environment variable, Cribl will not bind to a specified IPv6 address. 
               </p>
               <p>
                  <strong>Workaround</strong>: Manually update the settings in the two relevant configuration files, <a product="stream" href="https://docs.cribl.io/stream/instanceyml/" target="_blank">
                  <code>instance.yml</code>
                  </a> and <a product="stream" href="https://docs.cribl.io/stream/criblyml/" target="_blank">
                  <code>cribl.yml</code>
                  </a>, for RPC and UI communication respectively.
               </p>
               <p>For the UI, manually define the host setting in the <code>cribl.yml</code> file:</p>
               <div>
                  <div>
                     <pre>
<code>
api:
  host: "::"
</code>
</pre>
                  </div>
               </div>
               <p>To configure the instance as a Leader node and listen on all IPv6 and IPv4 addresses, manually configure the <code>instance.yml</code> file:</p>
               <div>
                  <div>
                     <pre>
<code>
distributed:
  mode: master
  master:
    host: "::"
    port: 4200
    tls:
      disabled: true
    authToken: criblmaster
</code>
</pre>
                  </div>
               </div>
               <p>
                  <strong>Fix</strong>: Version TBD.
               </p>
               <p />
               <hr />
               <h3>
                  2023-03-20 - v.3.5-4.1 - System Activity drawer on Windows Edge Nodes displays no data [CRIBL-16194]
               </h3>
               <p>
                  <strong>Problem</strong>: When you navigate to a Fleet's <strong>List View</strong> and click a row containing a Windows EdgeNode, the System Activity drawer displays no data. 
               </p>
               <p>
                  <strong>Fix</strong>: In CriblStream 4.1.1.
               </p>
               <p />
               <hr />
               <h3>
                  2023-03-20 - v.4.1 - If a deployment fails, Workers will not automatically revert to the previous version [CRIBL-16203]
               </h3>
               <p>
                  <strong>Problem</strong>: When a deployment fails, Workers cannot revert <code>default/cribl</code> to a previous version because that directory is no longer backed up. The Worker will enter a broken state if you provide an invalid deploy bundle, because it cannot revert to the last valid state.
               </p>
               <p>
                  <strong>Workaround</strong>: To resolve any broken Workers, you must deploy a valid configuration. The Worker will resume working once it picks up the new configuration.
               </p>
               <p>
                  <strong>Fix</strong>: Planned for CriblStream 4.1.3.
               </p>
               <p />
               <hr />
               <h3>
                  2023-03-15 - v.4.1 - QuickConnect Pipeline Settings button fails [CRIBL-16142]
               </h3>
               <p>
                  <strong>Problem</strong>: When adding a new Pipeline using QuickConnect, clicking the gear (⚙️) button fails to open PipelineSettings.
               </p>
               <p>
                  <strong>Workaround</strong>: After saving the Pipeline in QuickConnect, use <strong>Manage</strong> &gt; <strong>Processing</strong> &gt; <strong>Pipelines</strong> to select your new Pipeline. Click the gear button here to access PipelineSettings as expected.
               </p>
               <p>
                  <strong>Fix</strong>: In CriblStream 4.1.1.
               </p>
               <p />
               <hr />
               <h3>
                  2023-03-14 v.4.0-4.1 - Duplicate data with Event Hubs [CRIBL-16102]
               </h3>
               <p>
                  <strong>Problem</strong>: When <strong>Minimize Duplicates</strong> is enabled, the AzureEventHubs Source assigns partitions to multiple WorkerNodes in the same WorkerGroup, which generates duplicate data.
               </p>
               <p>
                  <strong>Workaround</strong>: Toggle <strong>Minimize Duplicates</strong> to <code>No</code> in <strong>Azure</strong> &gt; <strong>Event Hubs</strong> &gt; <strong>Advanced Settings</strong>.
               </p>
               <p>
                  <strong>Fix</strong>: In CriblStream 4.1.1.
               </p>
               <p />
               <hr />
               <h3>
                  2023-03-01 - v.4.0.4 - Kafka-based Sources are omitting the <code>_time</code> field [CRIBL-15696]
               </h3>
               <p>
                  <strong>Problem</strong>: Kafka-based Sources (Kafka, Azure Event Hubs, Confluent Cloud) are not sending the <code>_time</code> field.
               </p>
               <p>
                  <strong>Workaround</strong>: If CriblStream is not retrieving the <code>_time</code> field, then in the affected Sources' config modals, use the <strong>ProcessingSettings</strong> &gt; <strong>Fields</strong> tab to re-create <code>_time</code>. This new <code>_time</code> field will add the current (ingestion) time instead of the message time.
               </p>
               <p>
                  <strong>Fix</strong>: In CriblStream 4.1.
               </p>
               <p />
               <hr />
               <h3>
                  2023-02-24 - v.4.1 - The Chain Function has a 10% impact on performance [CRIBL-15538]
               </h3>
               <p>
                  <strong>Problem</strong>: Using the Chain Function to chain data processing from one Pipeline or Pack to another degrades performance by about 10%, compared to running the original Pipeline or Pack directly. 
               </p>
               <p>
                  <strong>Fix</strong>: Planned for CriblStream 4.2.
               </p>
               <p />
               <hr />
               <h3>
                  2023-02-23 - v.4.0.x - DNS Resolution reconnects Cribl TCP connections every time [CRIBL-15363]
               </h3>
               <p>
                  <strong>Problem</strong>: All Cribl TCP connections will reconnect every time DNS Resolution occurs, even when reconnection is not necessary.
               </p>
               <p>
                  <strong>Fix</strong>: In CriblStream 4.1.
               </p>
               <p />
               <hr />
               <h3>
                  2023-02-23 - v.4.0.4-4.1 - Enable Automatic Upgrades deletes remote repo's Git Settings [CRIBL-15502]
               </h3>
               <p>
                  <strong>Problem</strong>: Enabling the Leader's <strong>Upgrade</strong> &gt; <strong>EnableAutomatic Upgrade</strong> setting deletes the corresponding remote repo's stored <strong>GitSettings</strong>. 
               </p>
               <p>
                  <strong>Workaround</strong>: Reconfigure your repo at <strong>GitSettings</strong> &gt; <strong>Remote</strong>. 
               </p>
               <p>
                  <strong>Fix</strong>: Planned for CriblStream 4.1.3.
               </p>
               <p />
               <hr />
               <h3>
                  2023-02-22 - v.4.0.4-4.1 - Sending data to an inactive Kafka, Confluent Cloud, or Azure Event Hubs Destination triggers an endless series of log errors [CRIBL-15455]
               </h3>
               <p>
                  <strong>Problem</strong>: If you accidentally make a Kafka, Confluent Cloud, or Azure Event Hubs Destination inactive by putting a mismatched value in the <strong>Advanced Settings</strong> &gt; <strong>Environment</strong> setting, CriblStream will send an endless series of errors to the log file.
               </p>
               <p>
                  <strong>Workaround</strong>: Correct the <strong>Environment</strong> value or leave it empty.
               </p>
               <p>
                  <strong>Fix</strong>: In CriblStream 4.1.1.
               </p>
               <p />
               <hr />
               <h3>
                  2023-02-20 - v.4.0.x-4.1 - Logging-level changes do not take effect for services [CRIBL-15365]
               </h3>
               <p>
                  <strong>Problem</strong>: Changing logging levels in the Leader's Settings has no effect on the logs for the Connections, LeaseRenewal, Metrics, or Notifications services.
               </p>
               <p>
                  <strong>Fix</strong>: In CriblStream 4.1.1.
               </p>
               <p />
               <hr />
               <h3>
                  2023-02-20 - v.4.0.3-4.1 - On-prem WorkerNodes automatically upgrade, ignoring Leader settings [CRIBL-15367]
               </h3>
               <p>
                  <strong>Problem</strong>: Upgrading a Leader Node causes its on-prem WorkerNodes to automatically upgrade, even when the Leader's <strong>Enableautomaticupgrades</strong> option is set to <code>No</code> (the default). This problem does not affect Cribl-managed Cloud WorkerNodes.
               </p>
               <p>
                  <strong>Workaround</strong>: 1. Toggle the UI's <strong>Enableautomaticupgrades</strong> slider to <code>Yes</code> and save the configuration; then slide it back to <code>No</code> and save again. Or:2. Edit <code>local/cribl/cribl.yml</code> to explicitly set <code>upgradeSettings.disableAutomaticUpgrade</code> to <code>true</code>. 
               </p>
               <p>
                  <strong>Fix</strong>: In CriblStream 4.1.1.
               </p>
               <p />
               <hr />
               <h3>
                  2023-02-14 - v.4.0.0-4.0.4 - Pipeline is deselected in QuickConnect after modification [CRIBL-15246]
               </h3>
               <p>
                  <strong>Problem</strong>: If you add a Pipeline in the QuickConnect UI, then modify it in the<strong>EditPipeline</strong> modal, the Pipeline is deselected in the <strong>AddPipelinetoConnection</strong> modal. If you then close the <strong>AddPipelinetoConnection</strong> modal, the Pipeline will disappear from the Route.
               </p>
               <p>
                  <strong>Workaround</strong>: Select the modified Pipeline in the <strong>AddPipelinetoConnection</strong> modal before closing it.
               </p>
               <p>
                  <strong>Fix</strong>: In CriblStream 4.1.
               </p>
               <p />
               <hr />
               <h3>
                  2023-02-14 - v.3.5.0-4.1 - Cannot clear Messages drawer while in GitOps Push mode [CRIBL-15239]
               </h3>
               <p>
                  <strong>Problem</strong>: When in GitOps <code>Push</code> mode, you cannot clear messages from the <strong>Messages</strong> drawer. CriblStream returns a <code>Forbidden</code> error.
               </p>
               <p>
                  <strong>Fix</strong>: Version TBD.
               </p>
               <p />
               <hr />
               <h3>
                  2023-02-06 - v.4.0.x-4.1 - Event Breaker timestamp extraction fails after configured time [CRIBL-15107]
               </h3>
               <p>
                  <strong>Problem</strong>: Event Breakers' timestamp extraction stops working after the Rule's configured <strong>Futuretimestampallowed</strong> value (if set). All subsequent events received get the current time as their timestamp.
               </p>
               <p>
                  <strong>Workaround</strong>: Set a sufficiently large value for <strong>Futuretimestampallowed</strong> - e.g., one year from the date you re/configure the rule. Alternately, restore normal timestamp extraction by restarting WorkerProcesses.
               </p>
               <p>
                  <strong>Fix</strong>: In CriblStream 4.1.1.
               </p>
               <p />
               <hr />
               <h3>
                  2023-02-05 - v.3.0.3-4.0.4 - <code>CRIBL_DIST_WORKER_PROXY</code> env var is ignored when Leader Node's Master URL is set via <code>instance.yml</code> [CRIBL-15540]
               </h3>
               <p>
                  <strong>Problem</strong>: Setting the CriblStream Leader's Master URL via <code>instance.yml</code> causes WorkerNodes to ignore the <code>CRIBL_DIST_WORKER_PROXY</code> env var. Instead of trying to connect to the proxy configured in <code>CRIBL_DIST_WORKER_PROXY</code>, WorkerNodes will try to connect to other entities (e.g., Leader Nodes) directly, producing unexpected results.
               </p>
               <p>
                  <strong>Workaround</strong>: Set the CriblStream Leader's Master URL via the <code>CRIBL_DIST_MASTER_URL</code> env var, rather than via <code>instance.yml</code>.
               </p>
               <p>
                  <strong>Fix</strong>: In CriblStream 4.1.
               </p>
               <p />
               <hr />
               <h3>
                  2023-02-03 - v.4.0-4.0.4 - Metrics blocklist can't be changed on a global level [CRIBL-15081]
               </h3>
               <p>
                  <strong>Problem</strong>: The Metrics blocklist cannot be modified from <strong>Settings</strong> &gt; <strong>Global Settings</strong> &gt; <strong>General Settings</strong> &gt; <strong>Limits</strong>.
               </p>
               <p>
                  <strong>Workaround</strong>: Edit the <code>limits.yml</code> file's <code>metricsFieldsBlacklist</code> element. Add the event fields for which you want to disable metrics collection; remove any event fields for which you want to restore metrics collection.
               </p>
               <p>
                  <strong>Fix</strong>: In CriblStream 4.1.
               </p>
               <p />
               <hr />
               <h3>
                  2023-01-26 - v.3.5.0-4.0.3 - Preview Full&gt;Send Out does not capture events [CRIBL-14914]
               </h3>
               <p>
                  <strong>Problem</strong>: Selecting a Sample Data file's <strong>PreviewFull</strong> &gt; <strong>Sendout</strong> option captures no events. This bug has been observed when capturing on Destinations.
               </p>
               <p>
                  <strong>Fix</strong>: In CriblStream 4.0.4.
               </p>
               <p> </p>
               <hr />
               <h3>
                  2023-01-25 - v.3.5.x-4.1 - Cascading problems when Windows EventLogs Source collects from <code>ForwardedEvents</code> channel [CRIBL-14869]
               </h3>
               <p>
                  <strong>Problem</strong>: Using the Windows EventLogs Source to collect events from a Windows <code>ForwardedEvents</code> channel can cause misattribution of logs to the local machine that hosts Cribl Edge, and undercollection of local logs from other logging channels (such as Security, System, or Application).
               </p>
               <p>
                  <strong>Workaround</strong>: Exclude the <code>ForwardedLogs</code> channel from your <strong>EventLogs</strong> selection.
               </p>
               <p>
                  <strong>Fix</strong>: Planned for CriblStream 4.3.
               </p>
               <p />
               <hr />
               <h3>
                  2023-01-17 - v.4.0.X-4.0.4 - GitOps Push/read-only confirmation banner has dead link [CRIBL-14681]
               </h3>
               <p>
                  <strong>Problem</strong>: After you enable GitOps <code>Push</code> mode, the resulting red confirmation banner contains a dead link labeled <strong>GitOpsWorkflow</strong>.
               </p>
               <p>
                  <strong>Workaround</strong>: To switch off <code>Push</code> mode, navigate to <strong>Settings</strong> &gt; <strong>Global</strong> &gt; <strong>GitSettings</strong>, and then set <strong>GitOpsworkflow</strong> back to <code>None</code>.
               </p>
               <p>
                  <strong>Fix</strong>: In CriblStream 4.1.
               </p>
               <p />
               <hr />
               <h3>
                  2023-01-12 - v.3.5.x-4.0.4 - Recently added Worker Nodes fail to appear on the Monitoring page [CRIBL-14627]
               </h3>
               <p>
                  <strong>Problem</strong>: When Worker Nodes are added, there may be a delay before the Worker count is updated on the Monitoring page.
               </p>
               <p>
                  <strong>Workaround</strong>: Refresh your web browser.
               </p>
               <p>
                  <strong>Fix</strong>: Version TBD.
               </p>
               <p> </p>
               <hr />
               <h3>
                  2023-01-10 - v.3.5.x-4.1 - Configuration updates not shared between primary and standby Leaders [CRIBL-12814, CRIBL-14556]
               </h3>
               <p>
                  <strong>Problem</strong>: With high availability/failover enabled, updates to the active Leader's configuration are not automatically synced to the standby Leader. Workers might not be able to connect to the standby Leader when it takes over.
               </p>
               <p>
                  <strong>Workaround</strong>: Use the filesystem to explicitly sync the updated <code>instance.yml</code> file across the two Leaders' hosts.
               </p>
               <p>
                  <strong>Fix</strong>: In - v.4.0.3, as an intermediate fix, enabling HA will prevent further UI-based changes to <strong>DistributedSettings</strong>. Thiswill enforce config changes via edits to portable <code>instance.yml</code> files. Version TBD for automatic synchronization between Leaders' hosts.
               </p>
               <p />
               <hr />
               <h3>
                  2023-01-02 - v.4.0-4.0.2 - Google Cloud Chronicle Destination drops changes in distributed deployments with custom log types [CRIBL-14453]
               </h3>
               <p>
                  <strong>Problem</strong>: A new Google Cloud Chronicle Destination with a custom log type might fail to save changes. This issue affects only distributed deployments.
               </p>
               <p>
                  <strong>Fix</strong>: In CriblStream 4.0.3.
               </p>
               <p> </p>
               <hr />
               <h3>
                  2022-12-15 - v.3.5.4-4.0.3 - Changes to a Lookup table on the Leader don't always propagate to WorkerNodes [CRIBL-14299]
               </h3>
               <p>
                  <strong>Problem</strong>: Modifying a Lookup table on the Leader doesn't always propagate the changes to WorkerNodes, even after clicking <strong>Commit</strong> and <strong>Deploy</strong>.
               </p>
               <p>
                  <strong>Workaround</strong>: Manually restart the WorkerNodes to refresh Lookup tables.
               </p>
               <p>
                  <strong>Fix</strong>: In CriblStream 4.0.4.
               </p>
               <p> </p>
               <hr />
               <h3>
                  2022-12-13 - v.4.0-4.1 - Default commit message missing for non-admin users [CRIBL-14239]
               </h3>
               <p>
                  <strong>Problem</strong>: For users who have <a url="roles/" anchor="#default-roles" href="https://docs.cribl.io/stream/roles/#default-roles" target="_blank">Roles</a> as high as <code>owner_all</code>, but not <code>admin</code>, the Commit modal fails to display any <strong>Defaultcommitmessage</strong> saved in <strong>GitSettings</strong>.
               </p>
               <p>
                  <strong>Workaround</strong>: Enter (or paste) a message per commit.
               </p>
               <p>
                  <strong>Fix</strong>: Version TBD.
               </p>
               <p />
               <hr />
               <h3>
                  2022-12-09 - v.4.0.1-4.0.2 - Users assigned the <code>owner_all</code> role cannot perform commits [CRIBL-14180]
               </h3>
               <p>
                  <strong>Problem</strong>: When a user with the <code>owner_all</code> role tries to perform a commit, the commit fails with the UI displaying a <code>Forbidden</code> modal.
               </p>
               <p>
                  <strong>Workaround</strong>: Modify the <code>GroupFull</code> policy, as follows:
               </p>
               <ol>
                  <li>
                     <p>As a user with the <code>owner_all</code> role, try a <code>POST/version/commit</code> API call with a request body of <code>{"message": "test: hello"}</code>. The commit should fail, and the request payload should be <code>{ message: "test: hello" }</code>.</p>
                  </li>
                  <li>
                     <p>If <code>$CRIBL_HOME/local/cribl/policies.yml</code> does not exist, copy <code>$CRIBL_HOME/default/cribl/policies.yml</code> to <code>$CRIBL_HOME/local/cribl/policies.yml</code>.</p>
                  </li>
                  <li>
                     <p>If your OS is Linux, run the command <code>chmod 0744 policies.yml</code>.</p>
                  </li>
                  <li>
                     <p>In <code>$CRIBL_HOME/local/cribl/policies.yml</code>, edit the <code>GroupFull</code> policy to match the following:</p>
                     <div>
                        <div>
                           <pre>
                    <code>
GroupFull:
  args:
    - groupName
  template:
    - PATCH /master/groups/${groupName}/deploy
    - GroupEdit ${groupName}
    - POST /version/commit
    - GET /version
    - GET /version/*

                    </code>
                  </pre>
                        </div>
                     </div>
                  </li>
                  <li>
                     <p>Now retry the <code>POST /version/commit</code> API call, again with a request body of <code>{ "message": "test: hello" }</code>. The commit should succeed, and the request payload should be <code>{ message: "test: hello", "group": "default", "effective": true }</code>.</p>
                  </li>
               </ol>
               <p>
                  <strong>Fix</strong>: In CriblStream 4.0.3.
               </p>
               <p />
               <hr />
               <h3>
                  2022-12-08 - v.4.0.1-4.0.2 - Landing page not displaying system metrics from EdgeNodes when teleporting from the Leader [CRIBL-14169]
               </h3>
               <p>
                  <strong>Problem</strong>: When you teleport from a Leader running v.4.0.1 or 4.0.2 to an Edge Node that's running v.4.0.0 or earlier, the system metrics for the landing page will not populate. This also affects the system metrics shown in the Node drawer for the honeycomb and Node ListView pages.
               </p>
               <p>
                  <strong>Workaround</strong>: Upgrade EdgeNodes to v.4.0.2 or higher.
               </p>
               <p>
                  <strong>Fix</strong>: In CriblStream 4.0.3.
               </p>
               <p />
               <hr />
               <h3>
                  2022-12-07 - v.4.0.1 - GoogleCloud Pub/Sub Source and Destination can break on field validation [CRIBL-14160]
               </h3>
               <p>
                  <strong>Problem</strong>: The Google Cloud Pub/Sub Source and Destination strictly validated entries in the <strong>TopicID</strong> and <strong>SubscriptionID</strong> fields. Ifyou entered a full path (rather than the expected ID substring) in these fields, this strict validation broke the integration and broke the UI.
               </p>
               <p>
                  <strong>Workaround</strong>: Trim <strong>TopicID</strong> and <strong>SubscriptionID</strong> field values to just the ID.
               </p>
               <p>
                  <strong>Fix</strong>: Validation is rolled back in CriblStream 4.0.2.
               </p>
               <p />
               <hr />
               <h3>
                  2022-12-01 - v.4.0.2 - CrowdStrike FDR Source needs 6-hour visibility timeout [CRIBL-14067]
               </h3>
               <p>
                  <strong>Problem</strong>: With its default <strong>Visibilitytimeoutseconds</strong> setting of <code>600</code> (10minutes), the CrowdStrikeFDR Source can accumulate large backlogs when pulling data from Crowdstrike buckets.
               </p>
               <p>
                  <strong>Workaround</strong>: Set the <strong>Visibilitytimeoutseconds</strong> to <code>6000</code> (6hours), as CrowdStrike recommends. Leave both <strong>Maxmessages</strong> and <strong>Numreceivers</strong> at their default <code>1</code> settings.
               </p>
               <p>
                  <strong>Fix</strong>: In CriblStream 4.0.3.
               </p>
               <p />
               <hr />
               <h3>
                  2022-12-01 - v.4.0 - Amazon S3 Source stops receiving data after upgrade [CRIBL-14093]
               </h3>
               <p>
                  <strong>Problem</strong>: Upgrading to CriblStream 4.0.0 can cause the AmazonS3 Source to stop receiving data. This is due to a race condition between (premature) SQS messaging versus the Source's initialization.
               </p>
               <p>
                  <strong>Workaround</strong>: Skip v.4.0.0 (or temporarily roll back to v.3.5.4).
               </p>
               <p>
                  <strong>Fix</strong>: In CriblStream 4.0.1.
               </p>
               <p> </p>
               <hr />
               <h3>
                  2022-11-30 - v.4.0.2 - QuickConnect-configured Sources' misleading "Enabled" status while disconnected [CRIBL-14041]
               </h3>
               <p>
                  <strong>Problem</strong>: As you configure a new Source from the QuickConnect UI, the Source's <strong>Enabled</strong> slider will initially switch to <code>Yes</code>. Thisis misleading, because the Source is not yet connected to a Destination, so no data can flow.
               </p>
               <p>
                  <strong>Workaround</strong>: Save the Source in its config drawer. This resets the <strong>Enabled</strong> slider to its accurate <code>No</code> status, until you connect the Source to a Destination.
               </p>
               <p>
                  <strong>Fix</strong>: In Cribl Stream 4.0.3.
               </p>
               <p> </p>
               <hr />
               <h3>
                  2022-11-28 v.4.0-4.0.2 - “Unknown config version” error can appear when deploying changes [CRIBL-13910]
               </h3>
               <p>
                  <strong>Problem</strong>: Attempting to commit and deploy a change can trigger errors of the form <code>Unknown config version: "[hash]"</code>.
               </p>
               <p>
                  <strong>Workaround</strong>: On the Leader's host, upgrade the <code>git</code> client to v.1.9.1 or later. 
               </p>
               <p>
                  <strong>Fix</strong>: In CriblStream 4.0.3.
               </p>
               <p> </p>
               <hr />
               <h3>
                  2022-11-28 - v.4.1 - Diag bundles might fail to download from teleported WorkerNodes [CRIBL-13999]
               </h3>
               <p>
                  <strong>Problem</strong>: When you're remotely accessing a WorkerNode's UI, diag bundles might fail to download from <strong>GlobalSettings</strong> &gt; <strong>Diagnostics</strong>.
               </p>
               <p>
                  <strong>Workaround</strong>: Refresh the page and <strong>Export</strong> the bundle again. Alternatively, log directly into the WorkerNode's UI before creating the diag.
               </p>
               <p>
                  <strong>Fix</strong>: Version TBD.
               </p>
               <p> </p>
               <hr />
               <h3>
                  2022-11-23 - All versions through 4.1.0 - WorkerNodes show incorrect configurations after upgrade or commit/deploy from Leader [CRIBL-13863, CRIBL-15507]
               </h3>
               <p>
                  <strong>Problem</strong>: When you commit and deploy changes from the Leader, WorkerNodes sometimes fail to automatically restart with the correct configuration changes.
               </p>
               <p>
                  <strong>Workaround</strong>: Manually restart the WorkerNodes.
               </p>
               <p>
                  <strong>Fix</strong>: In CriblStream 4.1.1.
               </p>
               <p />
               <hr />
               <h3>
                  2022-11-23 - v.4.0 - Teleported WorkerNodes don't display DistributedSettings or Diagnostics Settings [CRIBL-13868]
               </h3>
               <p>
                  <strong>Problem</strong>: When displayed via remote access from the Leader ("teleporting"), a Worker's/EdgeNode's <strong>Settings</strong> UI omits the <strong>DistributedSettings</strong> and <strong>Diagnostics</strong> left-nav links. This blocks remote access to features like <a url="securing-communications" href="https://docs.cribl.io/stream/securing-communications" target="_blank">configuringTLScommunications</a> between WorkerNode and Leader.
               </p>
               <p>
                  <strong>Workaround</strong>: Access the Worker's UI directly on its host's port 9000 (or other configured port). Asa precondition, you might need to undo any <a url="securing-and-monitoring/" anchor="#ui-access" href="https://docs.cribl.io/stream/securing-and-monitoring/#ui-access" target="_blank">DisableUIAccess</a> setting on the parent WorkerGroup.
               </p>
               <p>
                  <strong>Fix</strong>: In CriblStream 4.0.1.
               </p>
               <p />
               <hr />
               <h3>
                  2022-11-22 - v.3.2.0-4.0 - Chain Function creates extra Pipelines and Functions during initialization [CRIBL-13860]
               </h3>
               <p>
                  <strong>Problem</strong>: Under certain circumstances, when initializing, the Chain Function created multiple unneeded Pipelines and Functions.
               </p>
               <p>
                  <strong>Fix</strong>: In CriblStream 4.0.1.
               </p>
               <p />
               <hr />
               <h3>
                  2022-11-21 - v.4.0.0 - Metrics service unavailable [CRIBL-13826]
               </h3>
               <p>
                  <strong>Problem</strong>: The <a product="stream" href="https://docs.cribl.io/stream/monitoring" target="_blank">Monitoring</a> and
                  <a class="productLink_eOY2" product="edge" target="_blank" href="https://docs.cribl.io/edge/managing-edge-nodes">
                  Fleet
                  </a>
                  pages don't load, due to the <a href="https://man.archlinux.org/man/systemd-tmpfiles-clean.service.8" target="_blank" rel="noopener noreferrer">systemd-tmpfiles</a> service cleaning some of the Cribl socket files from the <code>/tmp/</code> directory.
               </p>
               <p>
                  <strong>Workaround</strong>: Stop the host system from cleaning the socket files from the <code>/tmp/cribl-*</code> directory. For example, on an Amazon EC2 instance, add a new file to <code>/etc/tmpfiles.d</code> with the line <code>X /tmp/cribl-*</code>. Then restart the tmpfiles cleanup service with: <code>systemctl restart systemd-tmpfiles-clean.service</code>. Finally, restart the Cribl server.
               </p>
               <p>
                  <strong>Fix</strong>: This issue no longer applies to Cloud.Cloud as of 4.0.1. On-prem customers should use the workaround, which will be added to the deployment documentation as a standard practice. 
               </p>
               <p />
               <hr />
               <h3>
                  2022-11-18 - v.4.0.0-4.0.3 - License usage visible only for current day [CRIBL-13811]
               </h3>
               <p>
                  <strong>Problem</strong>: In the listed versions, selecting <strong>Monitoring</strong> &gt; <strong>System</strong> &gt; <strong>License</strong> displays usage only for the current day.
               </p>
               <p>
                  <strong>Fix</strong>: In CriblStream v.4.0.4.
               </p>
               <p />
               <hr />
               <h3>
                  2022-11-16 - versions 3.4.0-4.0.4 - Source PQ in Smart mode can trigger excessive memory usage and OOM failures [CRIBL-13761]
               </h3>
               <p>
                  <strong>Problem</strong>: Enabling Source-side PersistentQueues in <a url="persistent-queues" anchor="#source-triggers" href="https://docs.cribl.io/stream/persistent-queues#source-triggers" target="_blank">Smartmode</a> can trigger excessive memory usage, leading to out-of-memory failures and WorkerNode instability.
               </p>
               <p>
                  <strong>Workaround</strong>: If you encounter OOM failures (most likely with high throughput), set PQ to <code>AlwaysOn</code> mode instead.
               </p>
               <p>
                  <strong>Fix</strong>: In CriblStream 4.1.
               </p>
               <p />
               <hr />
               <h3>
                  2022-11-14 - version 4.0 - <code>Forbidden</code> error banners mistakenly displayed to non-admin users [CRIBL-13681]
               </h3>
               <p>
                  <strong>Problem</strong>: Non-admin users (with the <code>reader_all</code> Role) are mistakenly shown a continuous string of <code>Forbidden</code> error banners. 
               </p>
               <p>
                  <strong>Workaround</strong>: Available upon request (documented in the ticket), but cumbersome. Cribl recommends upgrading instead.
               </p>
               <p>
                  <strong>Fix</strong>: In CriblStream 4.0.1.
               </p>
               <p> </p>
               <hr />
               <h3>
                  2022-11-13 - v.4.0-4.0.2 - Edge/Kubernetes Logs Source repeats logs due to incorrect timestamp [CRIBL-13900]
               </h3>
               <p>
                  <strong>Problem</strong>: The Kubernetes Logs Source is collecting redundant information for containers that don't emit their own timestamps. ThisSource assumes "current time" when the timestamps are missing, causing it to incorrectly stream older logs during restarts.
               </p>
               <p>
                  <strong>Fix</strong>: In Cribl Edge 4.0.3.
               </p>
               <p />
               <hr />
               <h3>
                  2022-11-08 - v.4.0 - CriblEdge honeycomb display doesn't render null values [CRIBL-13595]
               </h3>
               <p>
                  <strong>Problem</strong>: When you view EdgeNodes in <strong>MapView</strong>, a honeycomb displays values for each of the metrics you select in the <strong>Measure</strong> drop-down. When a value is null for a particular the EdgeNode, the honeycomb should display <code>null</code>; instead, the value incorrectly renders as <code>uli</code>.
               </p>
               <p>
                  <strong>Fix</strong>: In CriblStream 4.0.1.
               </p>
               <p />
               <hr />
               <h3>
                  2022-11-08 - v.4.0 - Broken in-app doc links [DOC-100]
               </h3>
               <p>
                  <strong>Problem</strong>: The following Sources have broken in-app help links:
                  <a class="productLink_eOY2" product="edge" target="_blank" href="https://docs.cribl.io/edge/sources-kubernetes-logs">
                  KubernetesLogs
                  </a>
                  ,
                  <a class="productLink_eOY2" product="edge" target="_blank" href="https://docs.cribl.io/edge/sources-kubernetes-metrics">
                  KubernetesMetrics
                  </a>
                  ,
                  <a class="productLink_eOY2" product="edge" target="_blank" href="https://docs.cribl.io/edge/sources-windows-event-logs">
                  WindowsEventLogs
                  </a>
                  , and
                  <a class="productLink_eOY2" product="edge" target="_blank" href="https://docs.cribl.io/edge/sources-windows-metrics">
                  WindowsMetrics
                  </a>
                  .
               </p>
               <p>
                  <strong>Workaround</strong>: Use the above links to access these Sources' <a href="https://docs.cribl.io/edge/" target="_blank" rel="noopener noreferrer">onlinedocumentation</a>.
               </p>
               <p>
                  <strong>Fix</strong>: In CriblStream 4.0.1.
               </p>
               <p> </p>
               <hr />
               <h3>
                  2022-11-07 - v.4.0.0 - Spurious “Secret decrypt failed with error" log messages appear after upgrade [CRIBL-13554]
               </h3>
               <p>
                  <strong>Problem</strong>: After upgrading to CriblStream 4.0.0, multiple <code>Secret decrypt failed with error</code> messages might appear in logs. These are spurious, and you can disregard them.
               </p>
               <p>
                  <strong>Fix</strong>: In CriblStream 4.0.1.
               </p>
               <p> </p>
               <hr />
               <h3>
                  2022-11-07 - v.4.0 - Upgrade status shown on Group Upgrade page doesn't match Global Settings [CRIBL-13566]
               </h3>
               <p>
                  <strong>Problem</strong>: The <strong>Enable automatic upgrades</strong> status shown on the <strong>Settings &gt; Group Upgrade</strong> page doesn't match the slider selection on the <strong>Settings &gt; Global Settings &gt; Upgrade</strong> tab. 
               </p>
               <p>
                  <strong>Workaround</strong>: View the <strong>Enable automatic upgrades</strong> slider on the <strong>Settings &gt; Global Settings &gt; Upgrade</strong> tab to verify the current upgrade status. 
               </p>
               <p>
                  <strong>Fix</strong>: In CriblStream 4.0.1.
               </p>
               <p> </p>
               <hr />
               <h3>
                  2022-11-04 - v.3.5.1-4.0.4 - Avg Thruput (Bytes Per Second) not displayed for internal logs or metrics [CRIBL-13530]
               </h3>
               <p>
                  <strong>Problem</strong>: No <strong>AvgThruput(BytesPerSecond)</strong> data is displayed on CriblInternal logs and metrics Sources' <strong>Charts</strong> tab, nor for these Sources on their attached Routes. This is by design, because CriblStream does not perform BPS calculations for internal logs or metrics. But the visual disparity can be confusing.
               </p>
               <p>
                  <strong>Fix</strong>: In CriblStream 4.1.
               </p>
               <p />
               <hr />
               <h3>
                  2022-11-03 - v.4.0 - Sorting by column on Manage &gt; WorkerNode page results in blank list [CRIBL-13505]
               </h3>
               <p>
                  <strong>Problem</strong>: When you click a column header on the <strong>Manage</strong> &gt; <strong>WorkerNode</strong> page, the list goes blank and rows are not sorted. 
               </p>
               <p>
                  <strong>Workaround</strong>: Click the heading a couple of times to refresh the list. 
               </p>
               <p>
                  <strong>Fix</strong>: In CriblStream 4.0.1.
               </p>
               <p> </p>
               <hr />
               <h3>
                  2022-11-01 - All versions through 4.1 - Source PQ in Smart mode could cause premature backpressure [CRIBL-13414]
               </h3>
               <p>
                  <strong>Problem</strong>: Source-side persistent queuing enabled in <code>Smart</code> mode might trigger backpressure before the configured maximum queue size is reached. For TCP Sources, this will send backpressure back to the sender. For Sources using the UDP protocol, it will cause events to be dropped.
               </p>
               <p>
                  <strong>Fix</strong>: Version TBD.
               </p>
               <p />
               <hr />
               <h3>
                  2022-11-01 - v.4.0-4.1 - Default AppScope Config file can't be restored when in use [CRIBL-13400]
               </h3>
               <p>
                  <strong>Problem</strong>: When the default AppScope Config file is assigned to an <a url="sources-appscope" anchor="#filter" href="https://docs.cribl.io/stream/sources-appscope#filter" target="_blank">AppScope Source filter</a>, you can't restore it to its default settings. You'll see an error message that the AppScope Config file is currently in use. 
               </p>
               <p>
                  <strong>Workaround</strong>: On the AppScope Source's <strong>AppScopeFilterSettings</strong> tab, delete the default AppScope Config from the <strong>Allowlist</strong>. Then, edit the AppScopeConfig Knowledge object to restore its default settings. You can now add this AppScope Config, with its restored settings, back to the AppScopeSource's Allowlist. 
               </p>
               <p>
                  <strong>Fix</strong>: Version TBD.
               </p>
               <p> </p>
               <hr />
               <h3>
                  2022-10-20 - v.4.1 - Pipelines with Clone and other Functions can show inconsistent total processing times [CRIBL-13125]
               </h3>
               <p>
                  <strong>Problem</strong>: For Pipelines containing both a Clone Function and an async Functions (like Redis), the PipelineDiagnostics modal's <strong>PipelineProfile</strong> &gt; <strong>ProcessTime</strong> graph will sum up the duration of all Functions' processing times. This sum can exceed the Pipeline's total duration displayed in the <strong>Summary</strong>. 
               </p>
               <p>
                  <strong>Fix</strong>: Version TBD.
               </p>
               <p />
               <hr />
               <h3>
                  2022-11-03 - v.4.0 - Git settings don't immediately populate Commit modals [CRIBL-13501]
               </h3>
               <p>
                  <strong>Problem</strong>: After you save Git settings (such as a default commit message), the new settings do not immediately appear in Commit/GitChanges modals.
               </p>
               <p>
                  <strong>Workaround</strong>: A hard or soft refresh will close the modal, but when you reopen it, it will reflect your new settings. 
               </p>
               <p>
                  <strong>Fix</strong>: In CriblStream 4.0.1.
               </p>
               <p />
               <hr />
               <h3>
                  2022-10-12 - All versions through 4.0 - Event preview can hide some fields [CRIBL-12914]
               </h3>
               <p>
                  <strong>Problem</strong>: Preview panes can hide some fields at the bottom of each event.
               </p>
               <p>
                  <strong>Workaround</strong>: Resize your browser window to give the preview pane more depth.
               </p>
               <p>
                  <strong>Fix</strong>: In CriblStream 4.0.
               </p>
               <p />
               <hr />
               <h3>
                  2022-10-11 - All versions through 4.1 - GitOps Push mode doesn't support adhoc Collection jobs [CRIBL-12868]
               </h3>
               <p>
                  <strong>Problem</strong>: If you've enabled the <a product="stream" href="https://docs.cribl.io/stream/gitops" target="_blank">GitOps</a> Push workflow, you will be unable to run adhoc <a product="stream" href="https://docs.cribl.io/stream/collectors-schedule-run" target="_blank">Collectionjobs</a>.
               </p>
               <p>
                  <strong>Workaround</strong>: There are two options. 1. Temporarily disable the Push workflow in your environment. 2.Create a scheduled Collection job (with a relaxed cron schedule) on your dev branch, and push it to production through your Push workflow.
               </p>
               <p>
                  <strong>Fix</strong>: Version TBD.
               </p>
               <p />
               <hr />
               <h3>
                  2022-10-04 - All versions through 3.5.4 - FileMonitor Source fails with high-volume logs and file rotation [CRIBL-12762]
               </h3>
               <p>
                  <strong>Problem</strong>: The File Monitor Source might stop reading logs from an open file, if the log rotation service renames that file.
               </p>
               <p>
                  <strong>Workaround</strong>: Restart the File Monitor Source.
               </p>
               <p>
                  <strong>Fix</strong>: In CriblStream 4.0.
               </p>
               <p />
               <hr />
               <h3>
                  2022-10-03 - All versions through 4.0 - New Help drawers open under pinned Help drawers [CRIBL-12737]
               </h3>
               <p>
                  <strong>Problem</strong>: If you've pinned a Help drawer open, it's possible to open additional Help drawers behind the pinned drawer. 
               </p>
               <p>
                  <strong>Workaround</strong>: Close the pinned drawer to see the newly opened drawer.
               </p>
               <p>
                  <strong>Fix</strong>: In CriblStream 4.1.
               </p>
               <p> </p>
               <hr />
               <h3>
                  2022-09-26 - All versions through 4.0 - Manage Groups/Fleets pages count Packs in Pipeline totals [CRIBL-12602]
               </h3>
               <p>
                  <strong>Problem</strong>: On the <strong>Manage Groups</strong> and <strong>ManageFleets</strong> pages, the <strong>Pipelines</strong> column overstates the actual number of Pipelines, because it includes Packs in each WorkerGroup's total count.
               </p>
               <p>
                  <strong>Workaround</strong>: For each WorkerGroup, click the link in its <strong>Pipelines</strong> column to see the WorkerGroup's actual list of Pipelines.
               </p>
               <p>
                  <strong>Fix</strong>: In CriblStream 4.0.1.
               </p>
               <p />
               <hr />
               <h3>
                  2022-09-19 - v.4.0 - Subfleet search doesn't return parent Fleets [CRIBL-12465]
               </h3>
               <p>
                  <strong>Problem</strong>: On the <strong>ManageFleets</strong> page's <strong>Fleets</strong> tab, searching for a Subfleet name returns only the Subfleet, without information about its parent Fleets.
               </p>
               <p>
                  <strong>Fix</strong>: In Cribl Edge 4.0.1.
               </p>
               <p />
               <hr />
               <h3>
                  2022-09-06 - v.3.3.0-3.5.4 - Load-balanced Destinations with PQ enabled: Buffer flush errors and memory leaks [CRIBL-12203]
               </h3>
               <p>
                  <strong>Problem</strong>: Destination logs might show errors of the form: <code>Attempted to flush previously flushed buffer token</code>. Nodata has been lost, but this will lead to a memory leak until the WorkerNode is restarted. This is most likely to occur when there are more available downstream hosts than a <strong>Maxconnections</strong> limit configured on the Destination.
               </p>
               <p>
                  <strong>Workaround</strong>: To prevent the bug from occurring, set <strong>Maxconnections</strong> to the default <code>0</code> (enabling unlimited connections). Thiswill ensure that all discovered hosts enter the connection pool. If you encounter the bug, restarting the affected WorkerNodes (or letting an OOM the killer do so) will clear the memory leak.
               </p>
               <p>
                  <strong>Fix</strong>: In Cribl Stream 4.0.
               </p>
               <p />
               <hr />
               <h3>
                  2022-08-29 - All versions through 3.5.3 - Sources reject connections on ACME certs with no Subject [CRIBL-12097]
               </h3>
               <p>
                  <strong>Problem</strong>: With multiple Sources, if you configure TLS mutual authentication using an ACME certificate with an empty <code>Subject</code> field, CriblStream will reject connections - even though RFC6125 allows for <code>Subject</code> to be empty. This affects: Splunk Sources, Cribl internal Sources, Syslog, TCP, TCP JSON, Metrics, HTTP/S, AmazonFirehose, ElasticsearchAPI, DataDog, Grafana, Loki, Prometheus, and Windows Event Forwarder.
               </p>
               <p>
                  <strong>Workaround</strong>: Enter any value in the certificate's <code>CN</code> field. Anyentry will cause CCriblStream to match on the certificate's SAN (<code>subjectAltName</code>) extension.
               </p>
               <p>
                  <strong>Fix</strong>: In CriblStream 4.0.
               </p>
               <p />
               <hr />
               <h3>
                  2022-08-20 - v.3.2.0-4.0.3 - Deleting or modifying default MappingRule reclassifies Cribl-managed Cloud Workers as hybrid Workers [CRIBL-11983]
               </h3>
               <p>
                  <strong>Problem</strong>: Cribl.Cloud's UI currently allows deleting or modifying the <code>default</code> MappingRule. By doing so, an admin can inadvertently reclassify Cribl-managed Cloud Workers as hybrid Workers. These might not be supported by your Cribl.Cloud plan.
               </p>
               <p>
                  <strong>Workaround</strong>: If you have an Enterprise plan, create a hybrid WorkerGroup to manage the resulting hybrid Workers.
               </p>
               <p>
                  <strong>Fix</strong>: In CriblStream 4.0.4.
               </p>
               <p />
               <hr />
               <h3>
                  2022-08-19 - v.3.5.1-3.5.4 - Using GitOps environment variables crashes the Leader [CRIBL-11972]
               </h3>
               <p>
                  <strong>Problem</strong>: Where deployments rely on <code>CRIBL_GIT_*</code> <a url="environment-variables" anchor="#bootstrap-variables" href="https://docs.cribl.io/stream/environment-variables#bootstrap-variables" target="_blank">environmentvariables</a>, the Leader might crash on startup. 
               </p>
               <p>
                  <strong>Workaround</strong> Restart the Leader, disabling the environment variables if necessary. 
               </p>
               <p>
                  <strong>Fix</strong>: In CriblStream 4.0.
               </p>
               <p />
               <hr />
               <h3>
                  2022-08-27 - All versions - Azure EventHubs Destination with PQ drops events when inbound data is interrupted [CRIBL-17661, replaces CRIBL-12649]
               </h3>
               <p>
                  <strong>Problem</strong>: When Azure EventHubs (and other Kafka-based Destinations) have persistentqueues (PQs) configured, an interruption of inbound data flow (e.g., due to network issues) can cause the Destination to start dropping events.
               </p>
               <p>
                  <strong>Workaround</strong>: On the Source whose events are being interrupted, configure an <a url="persistent-queues" anchor="#source" href="https://docs.cribl.io/stream/persistent-queues#source" target="_blank">AlwaysOn</a> persistentqueue. Thisbuffering will cause the Destination to drop fewer events. Note that persistent queuing will not engage until CriblStream has exhausted all attempts to send the data to the Kafka receiver.
               </p>
               <p>
                  <strong>Fix</strong>: Planned for CriblStream 4.2.
               </p>
               <p />
               <hr />
               <h3>
                  2022-08-25 - Versions 3.4.1-4.1 - Splunk LoadBalanced Destination degradation with acks enabled [CRIBL-12066]
               </h3>
               <p>
                  <strong>Problem</strong>: On a Splunk LoadBalanced Destination, enabling the <strong>Minimizein-flightdataloss</strong> (acknowledgments) field can cause high CPU drain and backpressure. 
               </p>
               <p>
                  <strong>Workaround</strong>: On the Splunk LB Destination's <strong>AdvancedSettings</strong> tab, <a url="destinations-splunk-lb" anchor="#ack" href="https://docs.cribl.io/stream/destinations-splunk-lb#ack" target="_blank">disable</a> <strong>Minimizein-flightdataloss</strong>. 
               </p>
               <p>
                  <strong>Fix</strong>: Planned for CriblStream 4.1.3.
               </p>
               <p />
               <hr />
               <h3>2022-08-16 - All versions through 3.5.3 - SplunkHEC shows higher outbound datavolume than other SplunkDestinations</h3>
               <p>
                  <strong>Problem</strong>: Events sent to the SplunkHEC Destination will show higher outbound data volume than the same events sent to the SplunkSingleInstance or SplunkLoadBalanced Destinations, which use the S2S binary protocol.
               </p>
               <p>
                  <strong>Fix</strong>: Version TBD.
               </p>
               <p />
               <hr />
               <h3>
                  2022-08-16 - v.3.1.2-3.4.1 - Auto timestamping randomly begins using current time [CRIBL-11925]
               </h3>
               <p>
                  <strong>Problem</strong>: After a random interval, the auto timestamping feature might insert the current time into the <code>_time</code> field instead of using the timestamp from the event.
               </p>
               <p>
                  <strong>Workarounds</strong>: Restart the Stream instances to temporarily remedy the problem, or enable an EventBreaker rule's Manual Timestamp Format option.
               </p>
               <p>
                  <strong>Fix</strong>: In CriblStream v.3.5.3.
               </p>
               <p />
               <hr />
               <h3>
                  2022-08-10 - v.3.5.1 - Changing Notification target type crashes NewTarget modal [CRIBL-11848]
               </h3>
               <p>
                  <strong>Problem</strong>: Changing the <strong>TargetType</strong> while configuring a new Notification target crashes the <strong>NewTarget</strong> modal. 
               </p>
               <p>
                  <strong>Workaround</strong>: Set the <strong>Targettype</strong> once only while the modal is open.
               </p>
               <p>
                  <strong>Fix</strong>: In CriblStream 3.5.3.
               </p>
               <p />
               <hr />
               <h3>
                  2022-08-08 - v.3.x-4.1 - <code>cidr-matcher</code> does not support IPv6 addresses [CRIBL-11767]
               </h3>
               <p>
                  <strong>Problem</strong>: The version of <code>cidr-matcher</code> supported by Cribl only supports IPv4 CIDR matching.
               </p>
               <p>
                  <strong>Fix</strong>: Planned for CriblStream 4.1.3.
               </p>
               <p />
               <hr />
               <h3>
                  2022-08-03 - v.3.5.0-3.5.1 - CriblHTTP and CriblTCP Sources are not enabled on Cribl.Cloud [SAAS-1905]
               </h3>
               <p>
                  <strong>Problem</strong>: Cribl.Cloud's ⚙️<strong>NetworkSettings</strong> &gt;: <strong>DataSources</strong> tab lists <strong>IngestAddress</strong> ports for the new CriblHTTP and CriblTCP Sources. However, these ports are not yet enabled.
               </p>
               <p>
                  <strong>Workaround</strong>: If you need these ports enabled before the next maintenance release, contact Cribl Support or your SolutionsEngineer.
               </p>
               <p>
                  <strong>Fix</strong>: In CriblStream 3.5.2.
               </p>
               <p />
               <hr />
               <h3>
                  2022-08-02 - v.3.3-3.5.1 - Managed EdgeNodes mistakenly display "Unregistered" button [CRIBL-11652]
               </h3>
               <p>
                  <strong>Problem</strong>: Managed Edge instances erroneously display an <strong>Unregistered</strong> button. Managed EdgeNodes cannot be registered, because they pull their registration/licensing information from the Leader. So this button should not appear.
               </p>
               <p>
                  <strong>Workaround</strong>: Ignore the scary button. Your managed EdgeNode has inherited its Leader's registration.
               </p>
               <p>
                  <strong>Fix</strong>: In CriblStream 3.5.2.
               </p>
               <p />
               <hr />
               <h3>
                  2022-08-02 - v.3.x through 3.5.1 - Cribl.Cloud displays unsupported Sharing settings [SAAS-1899]
               </h3>
               <p>
                  <strong>Problem</strong>: On Cribl.Cloud, CriblStream's <strong>GeneralSettings</strong> &gt; <strong>Upgrade&amp;ShareSettings</strong> display a <strong>Sharingandlivehelp</strong> toggle, even though you cannot turn off telemetry on Cribl- or customer-managed (hybrid) Cloud Workers.
               </p>
               <p>
                  <strong>Workaround</strong>: Ignore this toggle. The UI controls enable you to slide the toggle to <code>No</code> and save the result, but this will have no effect.
               </p>
               <p>
                  <strong>Fix</strong>: In CriblStream 3.5.2.
               </p>
               <p />
               <hr />
               <h3>
                  2022-07-21 - v.3.5.0-3.5.2 - JobInspector shows higher Bytes In than Monitoring dashboards [CRIBL-11482]
               </h3>
               <p>
                  <strong>Problem</strong>: The Job Inspector sometimes displays a higher byte count than other Monitoring dashboards display for the same collection job. The Job Inspector overstates the throughput because it disregards any Event Breakers and Filter expressions applied between initial collection and Pipelines.
               </p>
               <p>
                  <strong>Workaround</strong>: Rely on the Monitoring metrics to judge accurate data flow through Pipelines to downstream services.
               </p>
               <p>
                  <strong>Fix</strong>: In CriblStream 3.5.3.
               </p>
               <p />
               <hr />
               <h3>
                  2022-07-21 - v.3.4.0-3.5.1 - Data loss with Source-side persistent queueing enabled [CRIBL-11478]
               </h3>
               <p>
                  <strong>Problem</strong>: With Source-side PQ enabled, events got stuck and did not process through Pipelines. The root cause was a Rename Function that used wildcards to rename required internal fields (specifically, <code>__pqSliceId</code> and <code>__offset</code>).
               </p>
               <p>
                  <strong>Workaround</strong>: Where RenameFunctions potentially rename internal fields (especially via <strong>Renameexpressions</strong> that include wildcards), either disable PQ on Sources that feed the parent Pipeline, or test and narrow the expression to affect only the desired fields.
               </p>
               <p>
                  <strong>Fix</strong>: In CriblStream 3.5.2.
               </p>
               <p> </p>
               <hr />
               <h3>
                  2022-07-21 - v3.5.1 - Fake Pack appears after upgrading to v.3.5.1. [CRIBL-11481]
               </h3>
               <p>
                  <strong>Problem</strong>: After an upgrade to v.3.5.1., a new Pack appears on the <strong>ManagePacks</strong> page. This Pack has no <strong>DisplayName</strong> and no contents. 
               </p>
               <p>
                  <strong>Workaround</strong>: Delete the ghost Pack. 
               </p>
               <p>
                  <strong>Fix</strong>: Not observed as of CriblStream 4.0.
               </p>
               <p> </p>
               <hr />
               <h3>
                  2022-07-20 - v3.5.0-3.5.1 - ManageWorkerNodes page fails to lazy-load Workers when scrolled [CRIBL-11474]
               </h3>
               <p>
                  <strong>Problem</strong>: Scrolling the
                  <strong>
                  ManageWorkerNodes
                  </strong>
                  page fails to load more than 50 WorkerNodes.
               </p>
               <p>
                  <strong>Fix</strong>: In CriblStream 3.5.2.
               </p>
               <p> </p>
               <hr />
               <h3>
                  2022-07-20 - v3.5.0-4.0 - CriblEdge/Windows: Upgrading ignores existing mode (etc.) settings [CRIBL-11467]
               </h3>
               <p>
                  <strong>Problem</strong>: When re-running Windows installers on a system that hosts a previous Cribl version as a managed EdgeNode, the installer does not read the distributed mode or other settings. Thenew version might install as a Leader instance.
               </p>
               <p>
                  <strong>Workaround</strong>: Run the new version's installer using the
                  <a class="productLink_eOY2" product="edge" target="_blank" href="https://docs.cribl.io/edge/deploy-windows">
                  samemodeandotheroptions
                  </a>
                  you used when installing the preceding version.
               </p>
               <p>
                  <strong>Fix</strong>: In CriblStream 4.1.
               </p>
               <p> </p>
               <hr />
               <h3>
                  2022-07-19 - v.3.5.0-3.5.1 - CriblEdge/Windows: Syslog Source disallows UDP binding [CRIBL-11439]
               </h3>
               <p>
                  <strong>Problem</strong>: On CriblEdge/Windows, attempting to bind the Syslog Source to a UDP port might trigger an error of the form: <code>bind EADDRINUSE 0.0.0.0:&lt;port number&gt;</code>. The reason is that Edge currently does not fully support the <code>socket.bind</code> on Windows. 
               </p>
               <p>
                  <strong>Fix</strong>: In Cribl Stream 3.5.2.
               </p>
               <p> </p>
               <hr />
               <h3>
                  2022-07-13 - v.3.5.0-3.5.1 - CriblEdge: Fleet&gt; ListView tab doesn't correctly filter EdgeNodes [CRIBL-11183]
               </h3>
               <p>
                  <strong>Problem</strong>: A Fleet Home page's <strong>ListView</strong> tab doesn't correctly filter EdgeNodes. Thistab displays all the EdgeNodes across all Fleets, instead of only those assigned to the Fleet.
               </p>
               <p>
                  <strong>Workaround</strong>: The <strong>MapView</strong> page is filtered correctly.
               </p>
               <p>
                  <strong>Fix</strong>: In CriblEdge 3.5.2.
               </p>
               <p> </p>
               <hr />
               <h3>
                  2022-07-04 - All versions through v.3.4.2 - No extended characters in PublishMetrics Function &gt; Eventfieldname field [CRIBL-8968, CRIBL-10984]
               </h3>
               <p>
                  <strong>Problem</strong>: A PublishMetrics Function's <strong>Eventfieldname</strong> values should contain only letters, numbers, underscores (<code>_</code>), and <code>.</code> characters (to separate names in nested structures). Using other characters will cause the parent Pipeline to stop sending events. CriblStream 3.5.0 and above check for valid characters when you save the Function's configuration, butin prior versions, the invalid config will save without an error message - the failure will happen at runtime, with errors echoed only in the logs.
               </p>
               <p>
                  <strong>Workaround</strong>: Ensure that <strong>Eventfieldname</strong> values contain no extended characters.
               </p>
               <p>
                  <strong>Fix</strong>: In Cribl Edge 4.0.
               </p>
               <p />
               <hr />
               <h3>
                  2022-07-01 - All versions through 3.5.0 - S3-based Sources' unread Region triggers auth errors [CRIBL-10981]
               </h3>
               <p>
                  <strong>Problem</strong>: On AmazonS3-based Sources, if you concatenate the AWS Region into the <strong>Queue</strong> field's URL or ARN, the SQS client is correctly configured to that region, but the S3 client is not. You will see authentication errors of the form: <code>TheAWSAccessKeyID you provided does not exist in our records.</code>
               </p>
               <p>
                  <strong>Workaround</strong>: Explicitly set the <strong>Region</strong> drop-down, even if the URL/ARN already contains the same Region. 
               </p>
               <p>
                  <strong>Fix</strong>: In CriblStream 3.5.1.
               </p>
               <p />
               <hr />
               <h3>
                  2022-06-30 - All versions through 4.0 - Persistent queue with compression requires oversize maxqueue limit [CRIBL-10965]
               </h3>
               <p>
                  <strong>Problem</strong>: If you configure <a url="persistent-queues" anchor="#configuring" href="https://docs.cribl.io/stream/persistent-queues#configuring" target="_blank">persistentqueueing</a> to both enable <strong>Compression</strong> and set a <strong>Maxqueuesize</strong> limit, set that limit optimistically and monitor the results. Due to an error in computing the compression factor, CriblStream will not fully use <strong>Maxqueuesize</strong> values below or equal to the volume's available disk space. Thiscan lead to a mostly empty disk, lost data (either blocked or dropped), and/or excessive backpressure.
               </p>
               <p>
                  <strong>Workaround</strong>: With <strong>Compression</strong> enabled, set the <strong>Maxqueuesize</strong> to a value <strong>higher</strong> than the volume's total available physical disk space (disregarding compression). Alternatively, leave <strong>Maxqueuesize</strong> empty, to impose no limit. Monitoroverall throughput and the queue size (if PQ engages), to verify that CriblStream is maximizing the queue.
               </p>
               <p>
                  <strong>Fix</strong>: Version TBD.
               </p>
               <p> </p>
               <hr />
               <h3>
                  2022-06-29 - v.3.4.2-3.5.1 - Can't install a new CriblStream instance as a named user [CRIBL-10907, CRIBL-11457]
               </h3>
               <p>
                  <strong>Problem</strong>: Bootstrapping a new Leader or Worker with a command of this form fails, with no systemd service created: <code>criblboot-startenable-u&lt;username&gt;</code>
               </p>
               <p>The symptom is an error of the form: <code>error:founduser=0asownerforpath=/opt/cribl/local,expecteduid=1001.</code> This does not affect upgrades to existing instances.</p>
               <p>
                  <strong>Workaround</strong>: Issue the <code>[sudo] chown -R &lt;username&gt;: /opt/cribl</code> command a second time. Then reattempt the <code>criblboot-start</code> command.
               </p>
               <p>
                  <strong>Fix</strong>: In CriblStream 3.5.2.
               </p>
               <p> </p>
               <hr />
               <h3>
                  2022-06-28 - v.3.5.x - CriblEdge/Windows Limitation: Cannot upgrade EdgeNodes from the Leader's UI [CRIBL-10870]
               </h3>
               <p>
                  <strong>Problem</strong>: CriblEdge/Windows does not support upgrading EdgeNodes via the Leader's UI. 
               </p>
               <p>
                  <strong>Workaround</strong>: Re-run the
                  <a class="productLink_eOY2" product="edge" target="_blank" href="https://docs.cribl.io/edge/deploy-windows">
                  Windowsinstaller
                  </a>
                  on each EdgeNode, specifying the same installation options/parameters you used when installing the preceding version.
               </p>
               <p>
                  <strong>Fix</strong>: Planned for CriblStream 4.2.
               </p>
               <p />
               <hr />
               <h3>
                  2022-06-27 - v.3.3.0-3.5.0 - Edge vs. Stream conflict in <code>/tmp</code> directory [CRIBL-10806]
               </h3>
               <p>
                  <strong>Problem</strong>: If you install CriblEdge and CriblStream on the same machine or VM - e.g., running Edge as <code>root</code> and Stream as a <code>cribl</code> user - both services attempt to use the <code>tmp/cribl_temp</code> subdirectory. Starting Stream after Edge will throw an error of the form: <code>EPERM:operationnotpermitted, rmdir'/tmp/cribl_temp'</code>. Starting Edge after Stream will change the folder's ownership, blocking subsequent restarts of Stream.
               </p>
               <p>
                  <strong>Workaround</strong>: For either CriblEdge or CriblStream, set the <code>CRIBL_TMP_DIR</code> variable to a separate base subdirectory like <code>/tmp/stream/</code> or <code>/tmp/edge/</code> before starting the app.
               </p>
               <p>
                  <strong>Fix</strong>: CriblStream 3.5.2 and later set separate <code>tmp/</code> subdirectories by default.
               </p>
               <p> </p>
               <hr />
               <h3>
                  2022-06-24 - v.3.5.0 - Leader takes excessive time to report healthy status [CRIBL-10768, CRIBL-11127]
               </h3>
               <p>
                  <strong>Problem</strong>: Upgrading from v.3.4.x to v.3.5.0 tripled the latency before some Leaders reported healthy status. Thepresumed cause was that load time increased due to an accumulation of persistent metrics, which progressively increased with more WorkerNodes and more uptime. 
               </p>
               <p>
                  <strong>Workaround</strong>: If upgrading is not possible or insufficient, move the existing metrics subdirectory away from <code>$CRIBL_HOME/state/metrics/</code>. CriblStream will re-create that as an empty subdirectory, and begin accruing fresh metrics there.
               </p>
               <p>
                  <strong>Fix</strong>: In CriblStream 3.5.1.
               </p>
               <p />
               <hr />
               <h3>
                  2022-06-23 - v.3.5 - Logs not viewable at Worker Group level [CRIBL-10665]
               </h3>
               <p>
                  <strong>Problem</strong>: If you select <strong>Monitoring</strong> &gt; <strong>Logs</strong>, and then select a WorkerGroup from the drop-down at upper left, you might see no logs at the Group level. Instead, you will see an error banner of the form:<br />
                  <code>ENOENT:no such file or directory,scandir '/opt/cribl_data/failover/log/group/&lt;group-name&gt;'</code>
               </p>
               <p>
                  <strong>Workaround</strong>: From the drop-down at upper left, select individual WorkerNodes to view their logs.
               </p>
               <p>
                  <strong>Fix</strong>: In CriblStream 3.5.1.
               </p>
               <p />
               <hr />
               <h3>
                  2022-06-09 - v.4.0.x-4.1.0 - Edge Settings mistakenly display ProcessCount controls [CRIBL-10402]
               </h3>
               <p>
                  <strong>Problem</strong>: Edge Fleets' <strong>FleetSettings</strong> &gt; <strong>WorkerProcesses</strong> page incorrectly includes editable <strong>ProcessCount</strong> and <strong>MinimumProcessCount</strong> controls. Each EdgeNode is locked to <code>1</code> WorkerProcess, so changes to these fields' values will have no effect.
               </p>
               <p>
                  <strong>Workaround</strong>: Ignore these two fields.
               </p>
               <p>
                  <strong>Fix</strong>: In CriblStream 4.1.1.
               </p>
               <p />
               <hr />
               <h3>
                  2022-06-01 - v.3.4.2 - Bootstrapping fails to create SystemD service file, or starts wrong service [CRIBL-10250]
               </h3>
               <p>
                  <strong>Problem</strong>: <a url="deploy-workers" href="https://docs.cribl.io/stream/deploy-workers" target="_blank">Bootstrapping</a> a 3.4.2 Worker fails. The terminal displays no <code>Enabled Cribl to be managed by ...</code> confirmation message.
               </p>
               <p>
                  <strong>Workaround</strong>: Explicitly run the <code>boot-start</code> <a url="cli-reference/" anchor="#boot-start" href="https://docs.cribl.io/stream/cli-reference/#boot-start" target="_blank">CLIcommand</a>.
               </p>
               <p>
                  <strong>Fix</strong>: In CriblStream 3.5.1.
               </p>
               <p> </p>
               <hr />
               <h3>
                  2022-05-31 - v.3.4.2 - Cloning/loading Groups page breaks with <code>ConfigHelper service is not available...</code> error [CRIBL-10228, CRIBL-10229]
               </h3>
               <p>
                  <strong>Problem</strong>: After cloning a Group containing at least one Pack, the UI hangs with a spinning pinwheel and an error banner reading <code>ConfigHelper service is not available...</code>. The root cause is that cloning the Group failed to copy over the Pack, leaving the new Group with broken references to it. 
               </p>
               <p>
                  <strong>Workaround</strong>: Use the filesystem to manually copy missing Packs from the original Group to the cloned Group. If these Packs' contents are not needed in the new Group, it's sufficient to just create the parallel subdirectory with: <code>mkdir$CRIBL_HOME/groups/$destGroup/default/$packName</code>.
               </p>
               <p>
                  <strong>Fix</strong>: In CriblStream 3.5.
               </p>
               <p />
               <hr />
               <h3>
                  2022-05-19 - v.3.3.0-3.5.1 - System Metrics Source skips filesystem events on LVM volumes [CRIBL-10092]
               </h3>
               <p>
                  <strong>Problem</strong>: When monitoring LVM logical volumes, the System Metrics Source omits <code>node_filesystem_*</code> events.
               </p>
               <p>
                  <strong>Fix</strong>: In CriblStream 3.5.2.
               </p>
               <p />
               <hr />
               <h3>
                  2022-05-06 - v.3.5 - Running ~1,000 EdgeNodes crashes Leader [CRIBL-9859]
               </h3>
               <p>
                  <strong>Problem</strong>: Attempting to bring up approximately 1,000 EdgeNodes (even in small batches) can crash the Leader.
               </p>
               <p>
                  <strong>Workaround</strong>: To support up to 1,000 Nodes, apply this Node.js setting:<br />
                  <code>exportNODE_OPTIONS=--max-old-space-size=8192</code>
               </p>
               <p>
                  <strong>Fix</strong>: In CriblStream 4.0.
               </p>
               <p />
               <hr />
               <h3>
                  2022-04-28 - v.3.4.0-3.4.1 - RESTCollector Misinterprets <code>.</code> character in Response Attributes [CRIBL-9708]
               </h3>
               <p>
                  <strong>Problem</strong>: Where a <a product="stream" href="https://docs.cribl.io/stream/collectors-rest" target="_blank">RESTCollector</a>'s Response Attributes contain a <code>.</code> character, it misinterprets this as an attribute nested within an object, not a literal character. 
               </p>
               <p>
                  <strong>Workaround</strong>: If possible, use other Response Attributes to fetch the next page. Otherwise, skip this version, or downgrade to a known well-behaved version.
               </p>
               <p>
                  <strong>Fix</strong>: In CriblStream 3.4.2.
               </p>
               <p />
               <hr />
               <h3>
                  2022-04-27 - v.3.4.1 - Git Changes drop-down returns <code>InvalidDate</code> [CRIBL-9698]
               </h3>
               <p>
                  <strong>Problem</strong>: After opening the left nav's <strong>Changes</strong> fly-out, the <strong>Version</strong> drop-down can display <code>InvalidDate</code> instead of commits' dates.
               </p>
               <p>
                  <strong>Workaround</strong>: Upgrade your installed <code>git</code> client to v.2.1.1 or newer; or skip this CriblStream version.
               </p>
               <p>
                  <strong>Fix</strong>: In CriblStream 3.4.2.
               </p>
               <p />
               <hr />
               <h3>
                  2022-04-26 - v.3.4.1 - HTTP 500 error when git is absent [CRIBL-9684]
               </h3>
               <p>
                  <strong>Problem</strong>: A <code>500-Internal Server Error</code> error banner can indicate that <code>git</code> is not installed on CriblStream's host.
               </p>
               <p>
                  <strong>Workaround</strong>: <a product="stream" href="https://docs.cribl.io/stream/version-control#git-installation" target="_blank">Install</a> <code>git</code> on the Leader or single instance. Onaffected WorkerNodes, install<code>git</code>, followed by a <code>gitinit</code> and an empty push to a new <code>master</code> branch. Asimpler workaround for WorkerNodes is to just enable remote access (<a product="stream" href="https://docs.cribl.io/stream/deploy-distributed#worker-access" target="_blank">Stream</a>,
                  <a class="productLink_eOY2" product="edge" target="_blank" href="https://docs.cribl.io/edge/setting-up-leader-and-edge-nodes#edge-access">
                  Edge
                  </a>
                  ) from the Leader.
               </p>
               <p>
                  <strong>Fix</strong>: In CriblStream 3.4.2.
               </p>
               <p />
               <hr />
               <h3>
                  2022-04-22 - v.3.3.0 - DatadogAgent API key ignored when forwarding metrics to Datadog [CRIBL-9633]
               </h3>
               <p>
                  <strong>Problem</strong>: On a Datadog Destination, when <strong>AllowAPIkeyfromevents</strong> is set to <code>Yes</code>, the API key from a DatadogAgent Source is not correctly emitted with metric events sent to Datadog. Instead, CriblStream simply sends the static <strong>APIkey</strong> configured in the Destination. (Thisaffects metrics events only; other data types correctly forward the event's API key.)
               </p>
               <p>
                  <strong>Workaround</strong>: Set <strong>AllowAPIkeyfromevents</strong>. to <code>No</code>. Configure the desired API key in the Destination's static <strong>APIkey</strong> field. (Ifyou need multiple API keys, can create multiple Destinations, and route events to each based on the <code>__agent_api_key</code> field value. This value contains the Agent API key per event.)
               </p>
               <p>
                  <strong>Fix</strong>: In CriblStream 3.4.2.
               </p>
               <p />
               <hr />
               <h3>
                  2022-04-21 - v.3.4.1 - Failed restart, <code>Uncaught (in promise)</code> error, after changing Authentication settings [CRIBL-9614]
               </h3>
               <p>
                  <strong>Problem</strong>: After changing Authentication settings, or configuring an external auth provider, CriblStream might fail to restart. Indications are errors of the form: <code>Uncaught(inpromise) TypeError: Cannot read properties of undefined (reading 'workerRemoteAccess')</code>, or: <code>Uncaught(inpromise) TypeError: l.api is undefined</code>.
               </p>
               <p>
                  <strong>Workaround</strong>: Directly edit the <code>cribl.yml</code> <a url="criblyml" href="https://docs.cribl.io/stream/criblyml" target="_blank">file's</a> <code>auth:</code> section.
               </p>
               <p>
                  <strong>Fix</strong>: In CriblStream 3.4.2.
               </p>
               <p />
               <hr />
               <h3>
                  2022-04-21 - All versions - Cribl.Cloud login page distorted on iPad [SAAS-1141]
               </h3>
               <p>
                  <strong>Problem</strong>: On certain iPads, we've seen the Cribl.Cloud login page's left text column repeated twice more across the display. These unintended overlaps prevent you from selecting (or tabbing to) the <strong>LoginwithGoogle</strong> button.
               </p>
               <p>
                  <strong>Workaround</strong>: If you encounter this, the only current workarounds are to either use GoogleSSO on a desktop browser, or else use a different login method.
               </p>
               <p>
                  <strong>Fix</strong>: No planned fix.
               </p>
               <p />
               <hr />
               <h3>
                  2022-04-19 - v.3.3.0-3.4.2 - Spurious buffer token flush error in TCP-based Destinations with PQ enabled [CRIBL-9565]
               </h3>
               <p>
                  <strong>Problem</strong>: This error message can mistakenly appear in logs: <code>Attemptedto flush previouslyflushed buffertoken</code>. You can ignore it on TCP-based, load-balanced Destinations (SplunkLoadBalanced, TCPJSON, Syslog/TCP, and CriblStream) with persistent queueing enabled.
               </p>
               <p>
                  <strong>Fix</strong>: In CriblStream 3.5.
               </p>
               <p />
               <hr />
               <h3>
                  2022-04-18 - All versions - Upgrade Version List is Limited to Latest Version [CRIBL-9568]
               </h3>
               <p>
                  <strong>Problem</strong>: The <strong>ChooseVersion</strong> drop-down list displays the latest version only. This creates an issue when you want to incrementally upgrade between prior versions. 
               </p>
               <p>
                  <strong>Fix</strong>: Version TBD.
               </p>
               <p />
               <hr />
               <h3>
                  2022-04-18 - v.3.3.1-3.5.1 - LookupFunctions intermittently fail [CRIBL-9539]
               </h3>
               <p>
                  <strong>Problem</strong>: LookupFunctions within some Pipelines were skipped up to ~20% of the time. Restarting CriblStream resolves this temporarily, but the failure eventually resurfaces as the new session proceeds.
               </p>
               <p>
                  <strong>Workaround</strong>: Where a LookupFunction fails, substitute an EvalFunction, building a ternary JS expression around a <a url="cribl-reference" anchor="#lookup" href="https://docs.cribl.io/stream/cribl-reference#lookup" target="_blank">
                  <code>C.Lookup</code>
                  </a> method.
               </p>
               <p>
                  <strong>Fix</strong>: In CriblStream 4.0.1.
               </p>
               <p />
               <hr />
               <h3>
                  2022-04-15 - All versions - Git permission errors [CRIBL-9530]
               </h3>
               <p>
                  <strong>Problem</strong>: Multiple Linux distro's have backported a permissions-restriction patch from <code>git-2.35.1</code> to earlier versions, notably including Ubuntu 20.04LTS. If you see errors of the form <code>fatal: unsafe repository ('/opt/cribl' is owned by someone else)</code> on the command line or in the CriblStream UI, this indicates an ownership mismatch (current user versus file base) on the directory corresponding to <code>$CRIBL_HOME</code> or <code>$CRIBL_VOLUME_DIR</code>.
               </p>
               <p>
                  <strong>Workaround</strong>: Use <code>chown</code> to recursively set permissions on all files in <code>/opt/cribl/</code> (or in or <code>$CRIBL_VOLUME_DIR</code>'s target directory) to match the user running CriblStream.
               </p>
               <p>
                  <strong>Fix</strong>: In CriblStream 3.4.2.
               </p>
               <p />
               <hr />
               <h3>
                  2022-04-15 - v.3.4.0 - Workers report incomplete metrics [CRIBL-9524]
               </h3>
               <p>
                  <strong>Problem</strong>: After upgrading to v.3.4.0, WorkerNodes failed to report all metrics. Missingmetrics were logged with a warning of the form: <code>failedto report metrics</code>, and with a reason of the form: <code>Cannotreadproperty'size' of undefined</code>.
               </p>
               <p>
                  <strong>Fix</strong>: In CriblStream 3.4.1.
               </p>
               <p />
               <hr />
               <h3>
                  2022-04-14 - v.3.4.0 - Monitoring visualizations lack color indicators [CRIBL-9510]
               </h3>
               <p>
                  <strong>Problem</strong>: When you hover over the Monitoring page's graphs, the expected red/yellow/green status indicators are missing.
               </p>
               <p>
                  <strong>Fix</strong>: In CriblStream 3.4.2.
               </p>
               <p />
               <hr />
               <h3>
                  2022-04-07 - v.3.4.0-3.4.1 - ChainFunction referencing a Pack triggers errors on Pack's Functions [CRIBL-9235]
               </h3>
               <p>
                  <strong>Problem</strong>: After you define a ChainFunction that references a Pack, Functions on Pipelines within that Pack will throw errors of the form: <code>Failedtoload. Function &lt;Function-name&gt; is missing. Please fix, disable, or remove the Function.</code> You might also find that you cannot add more Functions within the Pack. (However, data might continue to flow, despite these errors.)
               </p>
               <p>
                  <strong>Workaround</strong>: Remove the Chain Function, or its Pack reference. Refactor your flow logic to avoid this combination.
               </p>
               <p>
                  <strong>Fix</strong>: In CriblStream 3.4.2.
               </p>
               <p />
               <hr />
               <h3>
                  2022-04-05 - v.3.4.0 - Upgrade to 3.4.0 disables Worker/Node UI access [CRIBL-9175]
               </h3>
               <p>
                  <strong>Problem</strong>: Upon upgrading to v.3.4.0, even if the (prior, global) Worker/Node <strong>UIaccess</strong> option was set to <code>Yes</code>, the new per-WorkerGroup toggles are all set to <code>No</code> by default.
               </p>
               <p>
                  <strong>Workaround</strong>: On the
                  <strong>
                  ManageWorkerGroups
                  </strong>
                  page, re-enable the <strong>UIaccess</strong> toggles as desired. If these toggles are not displayed (with a Free license), edit <code>groups.yml</code> to add the key-value pair <code>workerRemoteAccess: true</code> within each desired WorkerGroup.
               </p>
               <p>
                  <strong>Fix</strong>: Version TBD.
               </p>
               <p />
               <hr />
               <h3>
                  2022-03-29 - v.3.4.0 - <code>this.dLogger.isSilly is not a function</code> errors [CRIBL-9019]
               </h3>
               <p>
                  <strong>Problem</strong>: Errors of this form have been observed with multiple triggers: 1.Disabling a customized Source or Destination (it remains enabled). 2.Importing and deleting a Pack. 3.Changing a channel's logging level.
               </p>
               <p>
                  <strong>Workaround</strong>: Delete and re-create affected Sources and Destinations. (No workaround has been identified for the Pack or logging errors.)
               </p>
               <p>
                  <strong>Fix</strong>: In 3.4.1.
               </p>
               <p />
               <hr />
               <h3>
                  2022-03-23 - v.3.4.0 - Monitoring page error in distributed environments with many WorkerNodes [CRIBL-8938]
               </h3>
               <p>
                  <strong>Problem</strong>: The Monitoring page displays an error where distributed environments have more than 30 WorkerNodes.
               </p>
               <p>
                  <strong>Fix</strong>: In 3.4.1.
               </p>
               <p />
               <hr />
               <h3>
                  2022-03-23 - Collect parameters values not evaluated as expressions [CRIBL-8932]
               </h3>
               <p>
                  <strong>Problem</strong>: In a <a product="stream" href="https://docs.cribl.io/stream/collectors-rest" target="_blank">RESTCollector</a>'s <strong>Collectparameters</strong> table, entering a parameter name like "earliest" as plain text will cause it to be interpreted as a literal string. This will not be evaluated as the <code>earliest</code> time-range parameter.
               </p>
               <p>
                  <strong>Workaround</strong>: Backtick the parameter name, e.g.: <code>`earliest`</code>. 
               </p>
               <p>
                  <strong>Fix</strong>: Tooltip clarified in CriblStream 4.0.
               </p>
               <p />
               <hr />
               <h3>
                  2022-03-23 - Upgrading v.3.3.1 Leader to v.3.4.0 blocks upgrade to Workers [CRIBL-8918]
               </h3>
               <p>
                  <strong>Problem</strong>: When you explicitly upgrade a Leader Node to 3.4.0, you can't push upgrades to Workers. 
               </p>
               <p>
                  <strong>Workaround</strong>: Automatic upgrades work as expected. At <strong>Settings</strong> &gt; <strong>GlobalSettings</strong> &gt; <strong>System&gt; Upgrade</strong>, set <strong>DisableAutomaticupgrades</strong> to <code>No</code>. 
               </p>
               <p>
                  <strong>Fix</strong>: In 3.4.1.
               </p>
               <p />
               <hr />
               <h3>
                  2022-03-17 - All versions through 3.4.0 - Failed systemd restarts due to erroneous <code>ExecStopPost</code> command [CRIBL-8807]
               </h3>
               <p>
                  <strong>Problem</strong>: On systemd, the Cribl service can stop with an unsuccessful return code. This was caused by a malformed <code>ExecStopPost</code> command in Cribl's provided <code>cribl.service</code> file.
               </p>
               <p>
                  <strong>Workaround</strong>: In <code>cribl.service</code>, delete the whole <code>ExecStopPost=...</code> line, and change the <code>Restart</code> parameter's value from <code>on-failure</code> to <code>always</code>. (The first deletion necessitates the second change.)
               </p>
               <p>
                  <strong>Fix</strong>: Versions 3.4.1 and later install a <code>cribl.service</code> file incorporating both the above changes. <strong>Ifyou are upgrading from v.3.4.0 or earlier, and you notice dead Workers, check and update your existing <code>cribl.service</code> configuration to match the changes above.</strong>
               </p>
               <p />
               <hr />
               <h3>
                  2022-03-17 - v.3.4.0 - Source PQ re-engages while draining, causing blockage/backpressure [CRIBL-8800]
               </h3>
               <p>
                  <strong>Problem</strong>: A Source with Persistent Queueing enabled can mistakenly re-engage queueing while still draining its queue - leading to blocked throughput and backpressure. This occurs after a Destination goes offline and back online, once or more, leaving the Source in an undetermined queue state.
               </p>
               <p>
                  <strong>Workaround</strong>: Wait 60 seconds for another queue drain event, to see if PQ behavior goes back to normal. If the problem persists, restart CriblStream.
               </p>
               <p>
                  <strong>Fix</strong>: In CriblStream 3.4.1.
               </p>
               <p />
               <hr />
               <h3>
                  2022-03-17 - v.3.4.0 - Monitoring pages break without git [CRIBL-8799]
               </h3>
               <p>
                  <strong>Problem</strong>: Unless git is installed locally, two Monitoring pages fail to display, with errors of the form <code>Versioning not supported</code>. The pages are <strong>Monitoring</strong> &gt; <strong>Overview</strong> and <strong>Monitoring</strong> &gt; <strong>System</strong> &gt; <strong>Licensing</strong>. To resolve the errors, git must be installed even on single-instance deployments.
               </p>
               <p>
                  <strong>Workaround</strong>: <a product="stream" href="https://docs.cribl.io/stream/version-control#git-installation" target="_blank">Install git</a>.
               </p>
               <p>
                  <strong>Fix</strong>: In 3.4.1.
               </p>
               <p />
               <hr />
               <h3>
                  2022-03-16 - v.3.2.2 through 3.4.0 - Upgrading from earlier versions degrades performance [CRIBL-8784]
               </h3>
               <p>
                  <strong>Problem</strong>: After upgrading to any of the indicated versions, customers with active Splunk Destinations noticed that CPU load increased, triggering backpressure more readily.
               </p>
               <p>
                  <strong>Workaround</strong>: Skip these versions, or downgrade to a known well-behaved version.
               </p>
               <p>
                  <strong>Fix</strong>: In 3.4.1.
               </p>
               <p>
               </p>
               <hr />
               <h3>
                  2022-03-11 - v.3.4.0 - In Free versions, Worker/Node UI access can't be accessed via UI [CRIBL-8707, CRIBL-8945]
               </h3>
               <p>
                  <strong>Problem</strong>: In v.3.4, Cribl moved the Worker/Node <strong>UIaccess</strong> toggle from global ⚙️<strong>Settings</strong>&gt; <strong>System</strong>&gt; <strong>DistributedSettings</strong> to per-WorkerGroup toggles on the
                  <strong>
                  ManageWorkerGroups
                  </strong>
                  page. But with a Free license, these controls aren't displayed in the UI at all.
               </p>
               <p>
                  <strong>Workaround</strong>: Directly edit <code>groups.yml</code> to add the key-value pair <code>workerRemoteAccess: true</code> within each desired WorkerGroup.
               </p>
               <p>
                  <strong>Fix</strong>: In 3.4.1.
               </p>
               <p />
               <hr />
               <h3>
                  2022-03-08 - versions 3.3.1-4.0 - GitOps + License expiration = Catch-22 [CRIBL-8600]
               </h3>
               <p>
                  <strong>Problem</strong>: If your Enterprise license expires while you have enabled the <a url="gitops" anchor="#ui-options" href="https://docs.cribl.io/stream/gitops#ui-options" target="_blank">GitOpsPushworkflow</a>, you will encounter the following block: CriblStream is in read-only mode, triggering a <code>Forbidden</code> error when you try to update your license key. Butyou also cannot reset the workflow from <code>Push</code> to <code>None</code>, because the expired license disables GitOps features.
               </p>
               <p>
                  <strong>Workaround</strong>: Contact Cribl Support for help updating your license.
               </p>
               <p>
                  <strong>Fix</strong>: Version TBD.
               </p>
               <p />
               <hr />
               <h3>
                  2022-03-07 - versions 3.2.x through 3.4.x - Undercounted <code>total.in_bytes</code> dimension metrics [CRIBL-8572]
               </h3>
               <p>
                  <strong>Problem</strong>: The <code>cribl.logstream.total.in_bytes</code> dimension sent to Destinations can show a lower data volume (against license quota) than <code>cribl.logstream.index.in_bytes</code>. This latter <code>index.in_bytes</code> dimension displays the correct license usage, and matches what's reported on the <strong>Monitoring</strong> dashboard. 
               </p>
               <p>
                  <strong>Workaround</strong>: Within the <code>cribl_metrics_rollup</code> Pipeline that ships with CriblStream, disable the RollupMetrics Function.
               </p>
               <p>
                  <strong>Fix</strong>: Couldn't reproduce the error.
               </p>
               <p />
               <hr />
               <h3>
                  2022-03-03 - versions 3.3.x - ElasticsearchAPI Source (distributed mode) stops receiving data after upgrade to 3.3.x [CRIBL-8515]
               </h3>
               <p>
                  <strong>Problem</strong>: After upgrading a distributed deployment to version 3.3.x, the ElasticSearchAPI Source might stop receiving data. This occurs when your existing Source config's <strong>Authenticationtype</strong> was set to <code>AuthToken</code>. The root cause is a 3.3.x schema change that unset this auth type to <code>None</code>. 
               </p>
               <p>
                  <strong>Workaround</strong>: In the Elasticsearch API Source configuration, reset the <strong>Authenticationtype</strong> to <code>AuthToken</code>. Then commit and deploy the restored config.
               </p>
               <p>
                  <strong>Fix</strong>: In CriblStream 3.4.
               </p>
               <p />
               <hr />
               <h3>
                  2022-02-24 - versions 3.3.x - After upgrade to 3.3.0, ElasticSearch Destination can't write to indexes whose name includes <code>-</code> [CRIBL-8451]
               </h3>
               <p>
                  <strong>Problem</strong>: After upgrade to version 3.3.x, LogStream cannot send data to Elasticsearch indexes whose name includes a hyphen (<code>-</code>).
               </p>
               <p>
                  <strong>Workaround</strong>: In the Elasticsearch Destinations's <strong>IndexorDataStream</strong> field, surround these index names in "quotes" or backticks. 
               </p>
               <p>
                  <strong>Fix</strong>: LogStream 3.3.1 added format validation and error-checking.
               </p>
               <p />
               <hr />
               <h3>
                  2022-02-18 - versions 3.3.x - Worker/Leader communications blocked by untrusted TLS certificate after upgrade to 3.3.0 [CRIBL-8361]
               </h3>
               <p>
                  <strong>Problem</strong>: With TLS enabled on Worker/Leader communications, after an upgrade from LogStream 3.2.x to v.3.3.x, Workers might fail to communicate with the Leader due to an untrusted SSL certificate on the Leader. Logs will show <code>connectionerror</code>s of the form: <code>"unableto verify the first certificate"</code> or <code>selfsigned certificate in certificate chain</code>.
               </p>
               <p>
                  <strong>Workaround</strong>: On each affected Worker: In the <code>instance.yml</code> file's' <code>distributed:</code> <code>master:</code> <code>tls:</code> section, set: <code>"rejectUnauthorized: false"</code>. Then restart CriblStream.
               </p>
               <p>
                  <strong>Fix</strong>: In 3.4.1.
               </p>
               <p />
               <hr />
               <h3>
                  2022-02-18 - versions 3.3.x - Can't upgrade Workers to 3.3.x via UI [CRIBL-8346]
               </h3>
               <p>
                  <strong>Problem</strong>: Attempting to upgrade on-prem Workers to version 3.3.x via the UI can fail, with an error of the form: <code>Group&lt;group-name&gt; is a managed group</code>.
               </p>
               <p>
                  <strong>Workaround</strong>: Edit the Leader's <code>$CRIBL_HOME/local/cribl/groups.yml</code> file to delete all instances of the key-value pair <code>onPrem:false</code>. Then, resave the file and reload the Leader.
               </p>
               <p>
                  <strong>Fix</strong>: In CriblStream 3.4.
               </p>
               <p />
               <hr />
               <h3>
                  2022-02-17 - versions 3.2.2 through 3.3.x - REST Collector pagination fails on duplicate/nested attribute names [CRIBL-8352]
               </h3>
               <p>
                  <strong>Problem</strong>: The <a product="stream" href="https://docs.cribl.io/stream/collectors-rest" target="_blank">REST Collector</a> does not consistently differentiate between multiple (nested) attributes that share the same name. This can break pagination that relies on a <code>ResponseBodyAttribute</code>.
               </p>
               <p>
                  <strong>Workaround</strong>: If possible, select a different <a product="stream" href="https://docs.cribl.io/stream/collectors-rest#pagination" target="_blank">Pagination</a> method, or specify a unique attribute name.
               </p>
               <p>
                  <strong>Fix</strong>: In CriblStream 3.4.
               </p>
               <p />
               <hr />
               <h3>
                  2022-02-17 - v.3.3.0 - Do not configure InfluxDB Destination on LogStream 3.3.0 [CRIBL-8354]
               </h3>
               <p>
                  <strong>Problem</strong>: Configuring InfluxDB Destinations can fail on LogStream 3.3.0. This problem has been observed only on distributed deployments, and data does flow to InfluxDB. But the InfluxDB config will not appear in LogStream's UI, and the broken config will block editing of other Destinations.
               </p>
               <p>
                  <strong>Workaround</strong>: If you need to send data to InfluxDB, skip v.3.3.0, and wait for the next release. If you encounter the broken UI, edit <code>outputs.yml</code> to remove any <code>influxdb_output</code> sections, and then restart LogStream. This will unblock UI-based editing of other Destinations.
               </p>
               <p>
                  <strong>Fix</strong>: In LogStream 3.3.1.
               </p>
               <p />
               <hr />
               <h3>
                  2022-02-10 - All versions, 3.2.1+ - Syslog Source's previewed data doesn't proceed through Routes [CRIBL-8210]
               </h3>
               <p>
                  <strong>Problem</strong>: The Syslog Source's <strong>GeneralSettings</strong> &gt; <strong>InputID</strong> field's default filter expression is <code>__inputId.startsWith('syslog:in_syslog:')</code>. The same filter appears in the <strong>PreviewFull</strong> tab's <strong>EntryPoint</strong> drop-down, except without the final colon. This means that data sent using <strong>PreviewFull</strong>'s version of the filter will not go through Routes that use the <strong>InputID</strong> version.
               </p>
               <p>
                  <strong>Workaround</strong>: When sending data from <strong>PreviewFull</strong> to a Route, if both use the <code>syslog:in_syslog</code> filter, edit the Route's filter to remove the final colon. This will make the filter identical in both places, routing data correctly.
               </p>
               <p />
               <hr />
               <h3>
                  2022-02-10 - version 3.3 - Slow-Mo Notification Notifications [CRIBL-8205]
               </h3>
               <p>
                  <strong>Problem</strong>: After you <a url="notifications" anchor="#configuring-health" href="https://docs.cribl.io/stream/notifications#configuring-health" target="_blank">create a Notification</a> on a Destination, the new Notification might take up to several minutes to appear on the Destination config modal's <strong>Notifications</strong> tab.
               </p>
               <p>
                  <strong>Details</strong>: This delay has not been reproduced consistently. Some Notifications appear immediately.
               </p>
               <p>
                  <strong>Fix</strong>: In CriblStream 4.0.
               </p>
               <p />
               <hr />
               <h3>
                  2022-02-08 - versions 3.3.x - Missing event from DatadogAgent v.7.33.0+ [CRIBL-8132]
               </h3>
               <p>
                  <strong>Problem</strong>: If ingesting metrics from DatadogAgent 7.33.0 or later (i.e., you have set the <code>DD_DD_URL</code> environment variable or the <code>dd_url</code> YAML config key), LogStream's <a url="sources-datadog-agent" href="https://docs.cribl.io/stream/sources-datadog-agent" target="_blank">DatadogAgent Source</a> will not ingest <code>agent_metadata</code> events. This is due to a breaking change in DatadogAgent 7.33.0, which split out part of the prior <code>/intake/</code> endpoint into a new <code>/api/v1/metadata</code> endpoint.
               </p>
               <p>
                  <strong>Workaround</strong>: Use DatadogAgent v.7.32.4 or earlier.
               </p>
               <p>
                  <strong>Fix</strong>: In CriblStream 3.4.
               </p>
               <p />
               <hr />
               <h3>
                  2022-02-08 - All versions through 3.x - Syslog and Metrics Sources' default filter expression needs correction [CRIBL-8115]
               </h3>
               <p>
                  <strong>Problem</strong>: In the Syslog and Metrics Sources's <strong>Logs</strong> tab, the auto-generated filter expression (<code>channel=='input:in_syslog'</code>) is not specific enough and yields no results, because it doesn't address these Sources' two channels (<code>input:in_syslog:tcp</code> and <code>input:in_syslog:udp</code>). 
               </p>
               <p>
                  <strong>Workaround</strong>: Replace this default filter expression with <code>channel.startsWith('input:&lt;input_ID&gt;')</code>. Forexample: <code>channel.startsWith('input:in_syslog:')</code>.
               </p>
               <p>
                  <strong>Fix</strong>: In CriblStream 3.4.
               </p>
               <p />
               <hr />
               <h3>
                  2022-02-07 - v.3.2.2 - Okta integration fails after upgrading from v.3.1.3 to v.3.2.2 [CRIBL-8105]
               </h3>
               <p>
                  <strong>Problem</strong>: Okta (OpenIDConnect) authentication on CriblStream fails behind a proxy, when using environment variables (<code>http_proxy</code> or <code>https_proxy</code>).
               </p>
               <p>
                  <strong>Workaround</strong>: Configure the proxy to work in transparent mode, to bypass the <code>http*_proxy</code> variables. If the proxy is required, leave the <code>UserInfoURL</code> empty, and CriblStream can obtain user details from the <code>JWT token</code>.
               </p>
               <p>
                  <strong>Fix</strong>: In 3.4.1.
               </p>
               <p />
               <hr />
               <h3>
                  2022-02-04 - versions 3.2.2 through 3.4.0 - Mask Function slows down post-processing Pipeline [CRIBL-8043]
               </h3>
               <p>
                  <strong>Problem</strong>: A post-processing Pipeline with a Mask Function can slow down drastically, showing high CPU usage on Workers.
               </p>
               <p>
                  <strong>Workaround</strong>: If practical, promote the same Mask Function to a pre-processing or processing Pipeline. 
               </p>
               <p>
                  <strong>Fix</strong>: In CriblStream 3.4.1.
               </p>
               <p />
               <hr />
               <h3>
                  2022-2-03 - All versions - JSON Serialize Function in post-processing Pipeline won't process [CRIBL-8013]
               </h3>
               <p>
                  <strong>Problem</strong>: A JSON Serialize Function in a post-processing Pipeline will throw errors of the form: <code>Failed to process event in Function: Maximum call stack size exceeded</code>.
               </p>
               <p>
                  <strong>Workaround</strong>: Promote the Serialize Function to a processing Pipeline, upstream from the Destination.
               </p>
               <p>
                  <strong>Fix</strong>: In 3.4.1.
               </p>
               <p />
               <hr />
               <h3>
                  2022-02-02 - Versions 3.x-4.0 - Upgrading a Pack overwrites Lookup and sample-data customizations [CRIBL-7998]
               </h3>
               <p>
                  <strong>Problem</strong>: Upgrading a <a url="packs" href="https://docs.cribl.io/stream/packs" target="_blank">Pack</a> overwrites any customizations you've made to the Pack's original/default Lookup tables and sample-data files. 
               </p>
               <p>
                  <strong>Workaround</strong>: Duplicate the Pack's default Lookup tables and sample-data files, and customize your duplicate copies. Upgrading the Pack will not overwrite your local copies.
               </p>
               <p>
                  <strong>Fix</strong>: Version TBD.
               </p>
               <p />
               <hr />
               <h3>
                  2022-01-11 - v.3.2.2 - Git Collapse Actions disaggregates [CRIBL-7638]
               </h3>
               <p>
                  <strong>Problem</strong>: With <strong>GitSettings</strong> &gt; <strong>Collapsedactions</strong> enabled, the combined <strong>Commit &amp; Push</strong> button appears in the modal as expected, but then saving a new change splits it back into two separate buttons: <strong>Commit</strong> and <strong>Deploy</strong>. 
               </p>
               <p>
                  <strong>Workaround</strong>: Disable the <strong>Collapseactions</strong> setting, then commit and deploy separately.
               </p>
               <p>
                  <strong>Fix</strong>: In LogStream 3.3.
               </p>
               <p />
               <hr />
               <h3>
                  2022-01-19 - v.3.2.2 - Usernames containing certain letters cause some API requests to fail [CRIBL-7728]
               </h3>
               <p>
                  <strong>Problem</strong>: Usernames containing certain letters can cause some API requests to fail with an <code>Invalid character in header content ["cribl-user"]</code> error. This can happen even when the username is valid for an Identity Provider.
               </p>
               <p>
                  <strong>Workaround</strong>: In your usernames, make sure that the letters you use are limited to the letters in Latin alphabet no. 1 as defined in the <a href="https://en.wikipedia.org/wiki/ISO/IEC_8859-1" target="_blank" rel="noopener noreferrer">ISO/IEC 8859-1</a> standard.
               </p>
               <p>
                  <strong>Fix</strong>: In LogStream 3.3. 
               </p>
               <p />
               <hr />
               <h3>
                  2022-01-18 - versions 3.2.0 through 3.4.0 - Diagnostics &gt; SystemInfo page omits some entries [CRIBL-7731]
               </h3>
               <p>
                  <strong>Problem</strong>: In current CriblStream versions, the <strong>Diagnostics&gt; SystemInfo</strong> page/tab omits certain statistics (<code>sysctl</code>, <code>ulimits</code>, <code>networkstats</code>, etc.) that were previously displayed below the <code>cpus</code> and <code>nets</code> elements.
               </p>
               <p>
                  <strong>Workaround</strong>: The hidden information is nevertheless available within <a product="stream" href="https://docs.cribl.io/stream/diagnosing" target="_blank">diagnosticbundles</a>.
               </p>
               <p>
                  <strong>Fix</strong>: In CriblStream 3.4.1. 
               </p>
               <p />
               <hr />
               <h3>
                  2022-01-04 - v.3.2.x - Enabling GitOps deletes LogStream's <code>bin</code>, <code>logs</code>, and <code>pid</code>subdirectories [CRIBL-7513]
               </h3>
               <p>
                  <strong>Problem</strong>: Enabling <a product="stream" href="https://docs.cribl.io/stream/gitops" target="_blank">GitOps</a> with LogStream 3.2.x, via either CLI or UI, can cause the deletion of the <code>bin</code>, <code>logs</code>, and <code>pid</code>subdirectories. This disables LogStream. The root cause is that <code>git</code> versions 2.13.1 and lower did not fully respect paths listed in <code>.gitignore</code>.
               </p>
               <p>
                  <strong>Workaround</strong>: Upgrade your <code>git</code> client to v.2.13.2 or higher, to correct the underlying behavior.
               </p>
               <p>
                  <strong>Fix</strong>: In LogStream 3.3.
               </p>
               <p />
               <hr />
               <h3>
                  2021-12-21 - v.3.2.2 through 4.0.x - Chain Function degrades CPU load and throughput [CRIBL-7445]
               </h3>
               <p>
                  <strong>Problem</strong>: Chaining Pipelines via the Chain Function can increase CPU load, and can signficantly slow down data throughput.
               </p>
               <p>
                  <strong>Workaround</strong>: Consolidate all Functions - per processing scenario - into a single Pipeline.
               </p>
               <p>
                  <strong>Fix</strong>: In CriblStream 4.1.
               </p>
               <p />
               <hr />
               <h3>
                  2021-12-15 - v.3.2.1 through 3.2.2 - Backpressure when writing to S3 and other file-based Destinations [CRIBL-7364]
               </h3>
               <p>
                  <strong>Problem</strong>: On file-based Destinations, enabling the <strong>Removestaging dirs</strong> toggle can trigger a race condition when inbound events per second reach a high rate. This leads to backpressure.
               </p>
               <p>
                  <strong>Workaround</strong>: Disable LogStream's native <strong>Removestaging dirs</strong> option. Instead, as the user running LogStream, set up a cron job like this:<br />
                  <code>crontab -e</code>
                  <br />
                  <code>0 1 * * * find &lt;stagingdir&gt; -type d -empty -mtime +1 -delete</code>
               </p>
               <p>
                  <strong>Fix</strong>: In LogStream 3.3.
               </p>
               <p />
               <hr />
               <h3>
                  2021-12-13 - v.2.4.4 through 3.1.1 - Upgrades via UI delete sample files [CRIBL-7347]
               </h3>
               <p>
                  <strong>Problem</strong>: Using the UI to upgrade LogStream versions prior to 3.1.2 will silently delete sample data files created by users. This affects using a Leader's UI (any version) to upgrade Workers running LogStream version 3.1.1 or earlier. Italso affects using the UI to upgrade the Leader itself, or a Single-Instance deployment, from v.3.1.1 or earlier to any newer version.
               </p>
               <p>
                  <strong>Workarounds</strong>: 1. Upgrade pre-3.1.2 versions <a product="stream" href="https://docs.cribl.io/stream/upgrading#distributed" target="_blank">via the filesystem</a>. 2. If you choose to upgrade pre-3.1.2 versions via the UI, first <a product="stream" href="https://docs.cribl.io/stream/data-preview#save-submenu" target="_blank">save to the filesystem</a> any custom sample files that you want to preserve. (Or, to copy directly from the filesystem, LogStream stores sample files internally at <code>$CRIBL_HOME/data/samples</code>, and stores an index of all sample files in <code>/$CRIBL_HOME/local/cribl/samples.yml</code>.)
               </p>
               <p>
                  <strong>Fix</strong>: Does not affect Workers running Cribl Stream (LogStream) 3.1.2 or higher. Does not affect self-upgrades of Leaders or Single Instances running v.3.1.2 or higher.
               </p>
               <hr />
               <h3>2021-12-10 - All Versions - API Reference is temporarily unstyled</h3>
               <p>
                  <strong>Problem</strong>: Our documentation's <a href="https://docs.cribl.io/api?v=4.1" target="_blank">APIReference</a> has temporarily lost some visual styling, while we swap in a new rendering component.
               </p>
               <p>
                  <strong>Workaround</strong>: Manually expand accordions, as needed.
               </p>
               <p>
                  <strong>Fix</strong>: Published as of 12/20/2021.
               </p>
               <p />
               <hr />
               <h3>
                  2021-12-09 - v.3.2.1 - File-based Destinations display an unavailable Persistent Queue option [CRIBL-7293]
               </h3>
               <p>
                  <strong>Problem</strong>: File-based Destinations' <strong>Backpressurebehavior</strong> drop-down misleadingly displays a <code>PersistentQueue</code> option, which is not really available on these Destinations. (Applies to Filesystem and some Amazon, Azure, and Google Cloud Destinations.) Selecting this option displays an error, and the configuration cannot be saved.
               </p>
               <p>
                  <strong>Workaround</strong>: Don't fall for clicking that fake <code>PersistentQueue</code> option.
               </p>
               <p>
                  <strong>Fix</strong>: In LogStream 3.2.2.
               </p>
               <hr />
               <h3>2021-12-07 - v.3.2.1 - SystemMetrics Source's documentation doesn't open in Help drawer</h3>
               <p>
                  <strong>Problem</strong>: After clicking the SystemMetrics Source's Help link, the drawer displays the error: "Unableto load docs. Please check LogStream's online documentation instead." This Source's documentation is also missing from the 3.2.1 docs PDF.
               </p>
               <p>
                  <strong>Workaround</strong>: Go to the live <a url="sources-system-metrics" href="https://docs.cribl.io/stream/sources-system-metrics" target="_blank">SystemMetrics</a> docs page.
               </p>
               <p>
                  <strong>Fix</strong>: In LogStream 3.2.1, as duplicate of CRIBL-6319.
               </p>
               <p />
               <hr />
               <h3>
                  2021-12-07 - v3.1.2, 3.1.3 - Increasing CPU load over time [CRIBL-7268]
               </h3>
               <p>
                  <strong>Problem</strong>: CPU load increases over time, with a slow increase in memory usage. Restarting LogStream temporarily resolves these symptoms. The root cause is needlessly collecting a high volume of full-fidelity metrics from the CriblMetrics source. 
               </p>
               <p>
                  <strong>Workaround</strong>: Disable the CriblMetrics Source.
               </p>
               <p>
                  <strong>Fix</strong>: Upgrade to LogStream 3.2.1, which provides an option to disable the CriblMetrics Source's <strong>FullFidelity</strong> toggle.
               </p>
               <p />
               <hr />
               <h3>
                  2021-11-24 - v3.2.0 - With processing Pipelines in QuickConnect, PreviewFull doesn't show Functions' results [CRIBL-7113]
               </h3>
               <p>
                  <strong>Problem</strong>: If a processing Pipeline has been inserted between a QuickConnect Source and Destination, selecting the <strong>Pipelines</strong> page, and then selecting <strong>PreviewFull</strong> with a data sample, doesn't show the Pipeline's effects on the <strong>OUT</strong> tab. This affects only Pipelines inserted in a QuickConnect connection line. (Attaching a pre-processing Pipeline to a QuickConnect Source doesn't inhibit Preview.)
               </p>
               <p>
                  <strong>Workarounds</strong>: 1. Remove the Pipeline from QuickConnect, and re-create the same Source -&gt; Pipeline -&gt; Destination architecture under <strong>Routing</strong>&gt; <strong>DataRoutes</strong>. 2.Rely on <strong>PreviewSimple</strong>.
               </p>
               <p>
                  <strong>Fix</strong>: Version TBD.
               </p>
               <p />
               <hr />
               <h3>
                  2021-11-24 - v3.2.0 - Data from Collectors and Collector-based Sources isn't reaching Routes [CRIBL-7109]
               </h3>
               <p>
                  <strong>Problem</strong>: Routes are not recognizing data from <a product="stream" href="https://docs.cribl.io/stream/collectors" target="_blank">Collectors</a> and from the following Collector-based <a url="sources" href="https://docs.cribl.io/stream/sources" target="_blank">Sources</a>: Prometheus Scraper, Office 365 Activity, Office 365 Services, and Office 365 Message Trace. This data will not flow through Routes, but <strong>will</strong> be sent to the default Destination(s).
               </p>
               <p>
                  <strong>Workarounds</strong>: 1. In Collectors' config modals, open the <strong>ResultRouting</strong> tab, Disable the <strong>SendtoRoutes</strong> default, and directly specify a <strong>Pipeline</strong> and <strong>Destination</strong>. (This option is not available in PrometheusScraper or in the Office365 Sources.) 2.Skip v.3.2.0.
               </p>
               <p>
                  <strong>Fix</strong>: In LogStream 3.2.1.
               </p>
               <p />
               <hr />
               <h3>
                  2021-11-17 - v3.2.0 - TLS certs that use passphrases won't decrypt private keys [CRIBL-7049]
               </h3>
               <p>
                  <strong>Problem</strong>: Sources whose TLS config uses a (known good) passphrase will fail to decrypt private keys. Youwill see a connect error, or an error of the form: <code>TLSvalidation error, is passphrase correct?</code>
               </p>
               <p>
                  <strong>Workarounds</strong>: 1. Edit the Leader's or single instance's <code>inputs.yml</code> file to insert a plaintext TLS passphrase. (Seepaths <a url="configuration-files" href="https://docs.cribl.io/stream/configuration-files" target="_blank">here</a>.) Thencommit and deploy the new config (distributed mode), or reload or restart the LogStream server (single instance). 2.Use a cert and key that do not require a passphrase. 3.Skip v.3.2.0.
               </p>
               <p>
                  <strong>Fix</strong>: In LogStream 3.2.1.
               </p>
               <p />
               <hr />
               <h3>
                  2021-11-17 - v3.2.0 - Only one Chain Function works per Pipeline [CRIBL-7044]
               </h3>
               <p>
                  <strong>Problem</strong>: If you add more than one Chain Function to a Pipeline, only the first will take effect. Chain Functions lower in the stack will simply pass the data down to the next Function.
               </p>
               <p>
                  <strong>Workaround</strong>: Design your data flow to require at most one Chain Function per Pipeline.
               </p>
               <p>
                  <strong>Fix</strong>: In 3.2.1.
               </p>
               <p />
               <hr />
               <h3>
                  2021-11-17 - v3.2.0 - Exporting a Pack to another Group requires a Leader restart [CRIBL-7043]
               </h3>
               <p>
                  <strong>Problem</strong>: Exporting a Pack to a different WorkerGroup via the UI succeeds, but opening the Pack on the target Group fails with a <code>Cannot read property...undefined</code> error.
               </p>
               <p>
                  <strong>Workaround</strong>: To resolve the error and make the target Pack accessible, restart the Leader. To prevent the error, export and import the Pack as a file.
               </p>
               <p>
                  <strong>Fix</strong>: In LogStream 3.2.1.
               </p>
               <p />
               <hr />
               <h3>
                  2021-11-17 - versions 2.1 through 3.2.1 - Re-enabling a Function group mistakenly re-enables all its Functions [CRIBL-7053]
               </h3>
               <p>
                  <strong>Problem</strong>: When you change a Function group from disabled to enabled, all of its Functions are enabled, regardless of their individual enabled/disabled states when the group was disabled.
               </p>
               <p>
                  <strong>Workaround</strong>: Avoid disabling and re-enabling Functions as a group (e.g., for testing or stepwise debugging purposes).
               </p>
               <p>
                  <strong>Fix</strong>: Version TBD.
               </p>
               <p />
               <p />
               <hr />
               <h3>
                  2021-11-16 - v3.2.0 - QuickConnected Source goes to wrong Destination [CRIBL-7013, CRIBL-7047]
               </h3>
               <p>
                  <strong>Problem</strong>: Some QuickConnect connections send data to an unintended Destination. We've observed this in single-instance deployments that include the Cribl-supplied <code>cribl_metrics_rollup</code> Pipeline, or include other Pipelines/Packs with stateful Functions like RollupMetrics or Aggregations. Datawill either flow through Routes instead of your specified QuickConnect Destination, or will continue flowing to the original QuickConnect Destination after you drag the connection to a different Destination.
               </p>
               <p>
                  <strong>Workaround</strong>: Use the <strong>DataRoutes</strong> interface to manage the Pipeline and stateful Functions indicated above. Ifyour QuickConnect data doesn't oblige a changed QuickConnect Destination, restart LogStream. This will stop data flow to the unintended Destination, and redirect it to the intended Destination.
               </p>
               <p>
                  <strong>Fix</strong>: In CriblStream 3.2.1.
               </p>
               <p />
               <hr />
               <h3>
                  2021-11-10 - v.3.2.0 - GitOps <code>Push</code> workflow displayed unsupported Revert button [CRIBL-6961]
               </h3>
               <p>
                  <strong>Problem</strong>: When a GitOps <code>Push</code> workflow has placed the UI in read-only mode, the Commit UI displayed a <strong>Revert</strong> button, even though reverting changes was not supported. Pressing the button simply triggered an error message.
               </p>
               <p>
                  <strong>Fix</strong>: In CriblStream/LogStream 3.2.1.
               </p>
               <p />
               <hr />
               <h3>
                  2021-10-11 - versions 2.x through 3.2.1 - Collectors do not filter correctly by date/time range [CRIBL-6440]
               </h3>
               <p>
                  <strong>Problem</strong>: Collectors can retrieve data from undesired time ranges, instead of from the range specified. If paths are organized by date/time, this can also cause Collectors to retrieve data from the wrong paths. The root cause is that in the Collector's Run and Schedule configuration modals, time ranges are set based on the browser's time zone, whereas LogStream's backend assumes UTC.
               </p>
               <p>
                  <strong>Workaround</strong>: Offset the <strong>Earliest</strong> and <strong>Latest</strong> date/time values based on your browser's offset from UTC.
               </p>
               <p>
                  <strong>Fix</strong>: In CriblStream/LogStream 3.2.2 and later, the Run and Schedule modals provide a <strong>RangeTimezone</strong> drop-down to prevent these errors.
               </p>
               <p />
               <hr />
               <h3>
                  2021-10-06 - v3.1.2 - Monitoring page omits Collector Sources' data [CRIBL-6412]
               </h3>
               <p>
                  <strong>Problem</strong>: With functioning Office365Activity and Office365Services Sources, the JobInspector reports data being retrieved, and <strong>Monitoring</strong>&gt; <strong>Data</strong>&gt; <strong>Destinations</strong> reports data being sent out. However, <strong>Monitoring</strong>&gt; <strong>Data</strong>&gt; <strong>Sources</strong> falsely reports no data being received. The problem is isolated to this <strong>Sources</strong> page. It might also affect the Office365MessageTrace and PrometheusScraper Sources.
               </p>
               <p>
                  <strong>Workaround</strong>: Use the Source modal's <strong>LiveData</strong> tab, the <strong>Monitoring</strong>&gt; <strong>System</strong>&gt; <strong>JobInspector</strong> page, and/or the <strong>Monitoring</strong>&gt; <strong>Data</strong>&gt; <strong>Destinations</strong> page to monitor throughput.
               </p>
               <p>
                  <strong>Fix</strong>: In LogStream 3.1.3.
               </p>
               <p />
               <hr />
               <h3>
                  2021-10-02 - All v.3.2.x - Kafka with Kerberos causes Workers' continuous restart [CRIBL-6674]
               </h3>
               <p>
                  <strong>Problem</strong>: Configuring the Kafka Source or Destination with Kerberos authentication can send LogStream Workers into a continuous loop of restarts.
               </p>
               <p>
                  <strong>Workaround (multi-step)</strong>:<br />
                  1.In <code>krb5.conf</code>, set <code>dns_lookup_realm=false</code> and <code>dns_lookup_kdc=false</code>.<br />
                  2.From <code>krb5.conf</code>'s <code>[realms]</code> section, extract the realm name (from the element name) and the FQDN (from the <code>kdc</code> key's value, stripping any port number).<br />
                  3.Run <code>nslookup</code> on either or both of the realm name and the FQDN. E.g.: <code>nslookupmysubdomain.confluent.io</code> and <code>nslookupkdc.kerberos-123.local</code>.<br />
                  4.Add at least one of the returned IP addresses (which might be identical) to the <code>etc/hosts</code> file, as values in the format your platform expects.
               </p>
               <p>
                  <strong>Fix</strong>: Version TBD.
               </p>
               <p />
               <hr />
               <h3>
                  2021-09-30 - v.3.1.2 - High CPU load with CriblMetrics Source [CRIBL-6319]
               </h3>
               <p>
                  <strong>Problem</strong>: Enabling the CriblMetrics Source causes high event count and high CPU load.
               </p>
               <p>
                  <strong>Workaround</strong>: Adjust the <code>cribl_metrics_rollup</code>
                  pre-processing Pipeline to roll up a wider <strong>TimeWindow</strong> of metrics.
               </p>
               <p>
                  <strong>Fix</strong>: Upgrade to LogStream 3.2.1, which provides an option to disable the CriblMetrics Source's <strong>FullFidelity</strong> toggle. 
               </p>
               <p />
               <hr />
               <h3>
                  2021-09-29 - v.3.0.2, 3.1.1 - Memory leak with multiple Collectors [CRIBL-6310]
               </h3>
               <p>
                  <strong>Problem</strong>: Configuring multiple Collectors can lead to gradual but cumulative memory leaks. Dueto a caching error, the memory can be recovered only by restarting LogStream.
               </p>
               <p>
                  <strong>Workaround</strong>: Restart LogStream on the affected WorkerNodes.
               </p>
               <p>
                  <strong>Fix</strong>: In LogStream 3.1.3.
               </p>
               <p />
               <hr />
               <h3>
                  2021-09-21 - v3.1.1 - AzureBlobStorage Source/Destination authentication error on upgrade from v.3.0.4 [CRIBL-6236]
               </h3>
               <p>
                  <strong>Problem</strong>: Upon upgrading the Azure Blob Source and/or Destination from v.3.0.4 to v.3.1.1, you might receive an error of the form: <code>Unableto extract accountName with provided information.</code>
               </p>
               <p>
                  <strong>Workaround</strong>: Change the key, and then reset it back to your desired connection string.
               </p>
               <p>
                  <strong>Fix</strong>: Not observed as of CriblLogStream 3.1.1.
               </p>
               <p />
               <hr />
               <h3>
                  2021-09-15 - v.3.0.0-3.1.3 - High CPU usage with Google Cloud Pub/Sub Source [CRIBL-6182]
               </h3>
               <p>
                  <strong>Problem</strong>: The Google Cloud Pub/Sub Source substantially increases CPU usage, which stays high even after data stops flowing. This causes throughput degradation, and more-frequent <code>failed to acknowledge</code> errors.
               </p>
               <p>
                  <strong>Workaround</strong>: Configure the Google Cloud Pub/Sub Source's <strong>AdvancedSettings</strong> &gt; <strong>Maxbacklog</strong> to <code>1000</code>. 
               </p>
               <p>
                  <strong>Fix</strong>: In 3.2.0, which defaults the <strong>Maxbacklog</strong> to <code>1000</code>, and also relaxes the retry interval from 10 seconds to 30seconds.
               </p>
               <p />
               <hr />
               <h3>
                  2021-09-14 - v.3.1.1 - Modifying Collector &gt; Preview &gt; Capture settings can break Capture elsewhere [CRIBL-6166]
               </h3>
               <p>
                  <strong>Problem</strong>: Modifying the capture settings in a Collector's Run &gt; Preview &gt; Capture modal can improperly modify the Filter expression in Capture modals for other Collectors, Sources, and Routes/Pipelines.
               </p>
               <p>
                  <strong>Fix</strong>: In LogStream 3.1.2.
               </p>
               <p />
               <hr />
               <h3>
                  2021-09-10 - v.3.1.1 - Worker Group certificate name drop-down shows certificates from the Leader [CRIBL-6142]
               </h3>
               <p>
                  <strong>Problem</strong>: When configuring certificates at <strong>Groups</strong> &gt;<code>&lt;group-name&gt;</code> &gt; <strong>Settings</strong>&gt; <strong>APIServerSettings</strong> &gt; <strong>TLS</strong>, certificates configured on the Leader incorrectly appear on the <strong>Certificatename</strong> drop-down.
               </p>
               <p>
                  <strong>Fix</strong>: In LogStream 3.1.2.
               </p>
               <p />
               <hr />
               <h3>
                  2021-09-10 - v.3.1.1 - Git Collapsed Actions broken in 3.1.1 [CRIBL-6134]
               </h3>
               <p>
                  <strong>Problem</strong>: With <strong>Collapsed Actions</strong> enabled, clicking the <strong>Commit&amp;Push</strong> button has no effect. (The <strong>Commit&amp;Deploy</strong> button works properly.)
               </p>
               <p>
                  <strong>Workaround</strong>: Disable <strong>Collapsed Actions</strong>, to restore separate <strong>Commit</strong> and <strong>GitPush</strong> buttons.
               </p>
               <p>
                  <strong>Fix</strong>: In LogStream 3.1.2.
               </p>
               <p />
               <p />
               <hr />
               <h3>
                  2021-09-08 - All versions through v.3.1.1 - UDP support is currently IPv4-only [CRIBL-6106, CRIBL-6115]
               </h3>
               <p>
                  <strong>Problem</strong>: Where Sources and Destinations connect over UDP, they currently support IPv4 only, not IPv6. This applies to Syslog, Metrics, and SNMPTrap Sources; and to Syslog, SNMPTrap, StatsD, StatsDExtended, and Graphite Destinations.
               </p>
               <p>
                  <strong>Workaround</strong>: Integrate via IPv4 if possible.
               </p>
               <p>
                  <strong>Fix</strong>: UDP Sources and Destinations gained IPv6 support in LogStream 3.1.2.
               </p>
               <p />
               <hr />
               <h3>
                  2021-09-02 - v.3.1.0 - Google Pub/Sub authentication via proxy environment variable fails [CRIBL-6086]
               </h3>
               <p>
                  <strong>Problem</strong>: When LogStream's GoogleCloud Pub/Sub Source and Destination attempt authentication through a proxy, using the <code>https_proxy</code> environment variable, they send an HTTP request to <a href="http://www.googleapis.com:443/oauth2/v4/token" target="_blank" rel="noopener noreferrer">http://www.googleapis.com:443/oauth2/v4/token</a>. Thisrequest fails with 504/502 errors. The root cause is a mismatch in dependency libraries, whose correction has been identified, but requires broader testing.
               </p>
               <p>
                  <strong>Workaround</strong>: Configure the proxy in <code>transparent</code> mode, to avoid relying on environment variables.
               </p>
               <p>
                  <strong>Fix</strong>: In 3.1.2.
               </p>
               <p />
               <p />
               <hr />
               <h3>
                  2021-08-24 - v.3.1.0 - High CPU load with LogStream version 3.1.0 [CRIBL-6039, CRIBL-6044]
               </h3>
               <p>
                  <strong>Problem</strong>: LogStream 3.1.0 added code-execution safeguards that inadvertently increased CPU load, and decreased throughput, with several Functions and most expressions.
               </p>
               <p>
                  <strong>Workaround</strong>: Downgrade to version 3.0.4. 
               </p>
               <p>
                  <strong>Fix</strong>: Upgrade to version 3.1.1 or later.
               </p>
               <p />
               <hr />
               <h3>
                  2021-08-18 - v.3.1.0 - Clone Collector option broken [CRIBL-5977]
               </h3>
               <p>
                  <strong>Problem</strong>: Clicking a 3.1.0 Collector modal's <strong>CloneCollector</strong> button simply closes the modal. (Ifyou have unsaved changes, you'll first be challenged to confirm closing the parent modal - but the expected cloned modal won't open.)
               </p>
               <p>
                  <strong>Workaround</strong>: Click <strong>+AddNew</strong> to re-create your original Collector's config from scratch, adding any desired modifications.
               </p>
               <p>
                  <strong>Fix</strong>: In LogStream 3.1.1.
               </p>
               <p />
               <hr />
               <h3>
                  2021-08-18 - All versions through 3.1.0 - Tabbed code blocks broken on in-app docs [CRIBL-5972]
               </h3>
               <p>
                  <strong>Problem</strong>: When docs with tabbed code blocks are opened in the Help drawer, the default (leftmost) tab seizes focus. Other tabs will not display when clicked.
               </p>
               <p>
                  <strong>Workaround</strong>: Click the blue/linked page title atop the Help drawer to open the same page on <a href="https://docs.cribl.io/" target="_blank" rel="noopener noreferrer">docs.cribl.io</a>, where all tabs can be selected.
               </p>
               <p>
                  <strong>Fix</strong>: In LogStream 3.1.1.
               </p>
               <p />
               <hr />
               <h3>
                  2021-08-14 - v.3.1.0 - Splunk Load Balanced Destination does not migrate auth type [CRIBL-5940]
               </h3>
               <p>
                  <strong>Problem</strong>: In a Splunk Load Balanced Destination with <strong>Indexerdiscovery</strong> enabled and a corresponding <strong>Authtoken</strong> defined, upgrading to LogStream 3.1.0 corrupts the <strong>Authtoken</strong> field's value.
               </p>
               <p>
                  <strong>Workaround</strong>: Set the <strong>Authenticationmethod</strong> to <strong>Manual</strong> and resave the token's value.
               </p>
               <p>
                  <strong>Fix</strong>: In 3.1.1.
               </p>
               <p />
               <hr />
               <h3>
                  2021-08-11 - v.3.1.0 - <code>C.Secret()</code> values are undefined in Collectors [CRIBL-5926]
               </h3>
               <p>
                  <strong>Problem</strong>: Calling the <a product="stream" href="https://docs.cribl.io/stream/3.1/cribl-reference#secret" target="_blank">C.Secret()</a> internal method within a <a product="stream" href="https://docs.cribl.io/stream/collectors" target="_blank">Collector</a> field resolves incorrectly to an <code>undefined</code> substring. E.g.,in URL fields, <code>C.Secret()</code> values will resolve to <code>/undefined/</code> path substrings.
               </p>
               <p>
                  <strong>Workarounds</strong>: 1. Use <code>C.vars</code> and a Global Variable, instead of using this method. 2.Root cause is that <code>C.Secret()</code> in Collectors and Pipeline Functions has access only to secrets that were created before the last restart. Therefore, restart WorkerProcesses to refresh the method's access.
               </p>
               <p>
                  <strong>Fix</strong>: In 3.1.1.
               </p>
               <p />
               <hr />
               <h3>
                  2021-08-10 - v.3.1.0 - Pre-processing Pipelines break Flows display [CRIBL-5909]
               </h3>
               <p>
                  <strong>Problem</strong>: Attaching a pre-processing Pipeline to a Source breaks the <strong>Monitoring</strong>&gt; <strong>Flows(beta)</strong> page's display. Attempting to remove Sources/Destinations from that page's selectors throws a cryptic <code>Sankey</code> error.
               </p>
               <p>
                  <strong>Workaround</strong>: Temporarily detach pre-processing Pipelines if you want to check Flows.
               </p>
               <p>
                  <strong>Fix</strong>: Upgrade to version 3.1.1 or later.
               </p>
               <p />
               <hr />
               <h3>
                  2021-07-29 - v.3.0.2 through 3.0.4 - Upgrades via UI require broader permissions [CRIBL-5774]
               </h3>
               <p>
                  <strong>Problem</strong>: Upgrading from v.3.0.x via the UI requires the <code>cribl</code> user to be granted write permission on the parent directory above <code>$CRIBL_HOME</code>. Thesymptom is an error message of the form: <code>Upgrade failed: EACCES: permission denied, mkdir '/opt/unpack.xxxxxxx.tmp'</code>.
               </p>
               <p>
                  <strong>Workaround</strong>: Either adjust permissions, or upgrade via the filesystem. Forcomplete instructions, see <a product="stream" href="https://docs.cribl.io/stream/3.0.4/upgrading#CRIBL-5774" target="_blank">Upgrading</a>.
               </p>
               <p>
                  <strong>Fix</strong>: Does not affect LogStream 3.1 or higher.
               </p>
               <p />
               <hr />
               <h3>
                  2021-07-26 - v.3.0.x-3.1.0 - Packs with orphaned lookups block access to Worker Groups [CRIBL-5738]
               </h3>
               <p>
                  <strong>Problem</strong>: If a Pack references a lookup file that's missing from the Pack, pushing the Pack to a WorkerGroup will block access to the Group's UI. You will see an error message of the form: "TheConfigHelper service is not available because a configuration file doesn't exist... Please fix it and restart LogStream."
               </p>
               <p>
                  <strong>Workaround</strong>: On the Leader Node, review the confighelper logs (<code>$CRIBL_HOME/log/groups/&lt;group&gt;/*.log</code>) to see which references are broken. (Ina single-instance deployment, see <code>$CRIBL_HOME/log/*.log</code>.) Then manually resolve these references in the Pack's configuration.
               </p>
               <p>
                  <strong>Fix</strong>: Upgrade to version 3.1.1 or later.
               </p>
               <p />
               <hr />
               <h3>
                  2021-07-20 - v.3.0.3 - Can't add Functions to a Pipeline named <code>config</code> [CRIBL-5706]
               </h3>
               <p>
                  <strong>Problem</strong>: You cannot add Functions to a Pipeline if the Pipeline is named <code>config</code>, because this name conflicts with the reserved route for the <strong>CreatePipeline</strong> dialog.
               </p>
               <p>
                  <strong>Workarounds</strong>: Don'tcha name your Pipelines <code>config</code>.
               </p>
               <p>
                  <strong>Fix</strong>: In CriblStream 3.4.1.
               </p>
               <p />
               <hr />
               <h3>
                  2021-07-06 - All versions through 3.1.x - Duplicate Workers/WorkerGUIDs [CRIBL-5611]
               </h3>
               <p>
                  <strong>Problem</strong>: Multiple Workers have identical GUIDs. This creates problems in <a product="stream" href="https://docs.cribl.io/stream/monitoring" target="_blank">Monitoring</a>, <a url="upgrading" href="https://docs.cribl.io/stream/upgrading" target="_blank">upgrading</a> and versioning, etc., because all Workers show up as one.
               </p>
               <p>
                  <strong>Cause</strong>: This is caused by configuring one Worker and then copying its <code>cribl/</code> directory to other Workers, to quickly bootstrap a deployment.
               </p>
               <p>
                  <strong>Workaround</strong>: Don't do this! Instead, use the <a product="stream" href="https://docs.cribl.io/stream/deploy-workers" target="_blank">Bootstrap Workers from Leader</a> endpoint.
               </p>
               <p>
                  <strong>Fix</strong>: Version TBD.
               </p>
               <p />
               <hr />
               <h3>
                  2021-07-02 - v.3.0.2-3.0.3 - Sample file's last line not displayed upon upload [CRIBL-5595]
               </h3>
               <p>
                  <strong>Problem</strong>: When uploading (attaching) a sample data file, the file's final line is not displayed in the <strong>AddSampleData</strong> modal.
               </p>
               <p>
                  <strong>Workarounds</strong>: This is a UI bug only. LogStream correctly processes the complete sample data, which should show up when viewing the sample afterwards (e.g., within a Pipeline's preview pane).
               </p>
               <p>
                  <strong>Fix</strong>: In LogStream 3.1.0.
               </p>
               <p />
               <hr />
               <h3>
                  2021-07-02 - All versions - Date fields misleadingly preview with string symbol [CRIBL-5594]
               </h3>
               <p>
                  <strong>Problem</strong>: In <a url="data-preview" href="https://docs.cribl.io/stream/data-preview" target="_blank">Preview or Capture</a>, incoming events like <code>_raw</code> will be displayed in the right pane with an <code>α</code> symbol that indicates string data. However, calling <code>newDate()</code> and then <code>C.Time.strptime()</code> <a url="cribl-reference" anchor="#time" href="https://docs.cribl.io/stream/cribl-reference#time" target="_blank">methods</a> in an <a url="eval-function" href="https://docs.cribl.io/stream/eval-function" target="_blank">Eval</a> Function will return <code>null</code> on the OUT tab.
               </p>
               <p>
                  <strong>Cause</strong>: Due to the nature of JSON serialization, the incoming event's <code>Date</code> field is misleadingly subsumed under the event's <code>α</code> string symbol. It's actually a structured type, not a string...yet.
               </p>
               <p>
                  <strong>Workaround</strong>: If you see unexpected <code>null</code> results, stringify the datetime field as you extract it, e.g.: <code>new Date().toISOString()</code>. Feeding the resulting field to Time methods should return datetime strings as expected.
               </p>
               <p>
                  <strong>Fix</strong>: In LogStream 3.1.0.
               </p>
               <p />
               <hr />
               <h3>
                  2021-06-22 - v.3.0.0-3.0.2 - Internal <code>C.Text.relativeEntropy()</code> method - broken typeahead and preview [CRIBL-5534]
               </h3>
               <p>
                  <strong>Problem</strong>: The <code>C.Text.relativeEntropy()</code> internal method is missing from JavaScript expressions' typeahead drop-downs. You can manually type or paste in the method, and save your Function and Pipeline, but LogStream's right Preview pane will (misleadingly) always show the method returning <code>0</code>.
               </p>
               <p>
                  <strong>Workarounds</strong>: Use other means (such as the <strong>Live</strong> button) to preview and verify that the method is (in fact) returning valid results.
               </p>
               <p>
                  <strong>Fix</strong>: In LogStream 3.1.0.
               </p>
               <p />
               <p />
               <hr />
               <h3>
                  2021-05-20 - 3.0.0 - Multiple Functions Break LogStream 3.0 Pipelines [CRIBL-5311, CRIBL-5766]
               </h3>
               <p>
                  <strong>Problem</strong>: After upgrade to LogStream 3.0.0, including any of the following Functions in a Pipeline can break the Pipeline: GeoIP, Redis, DNSLookup, ReverseDNS, Tee. Symptom is an error of the form: <code>Pipeline process timeout has occurred.</code> Less seriously, including these Functions in a Pipeline can suppress Preview's display of fields/values.
               </p>
               <p>
                  <strong>Workarounds</strong>: If you use these Functions in your Pipelines, stay with (or restore) a pre-3.0 version until LogStream 3.0.1 is available.
               </p>
               <p>
                  <strong>Fix</strong>: CRIBL-5311 fixed in LogStream 3.0.1. CRIBL-5766 fixed in LogStream 3.2.1.
               </p>
               <hr />
               <h3>2021-05-19 - 3.0.0 - Leader's Changes fly-out stays open after Commit</h3>
               <p>
                  <strong>Problem</strong>: In the Leader's left nav, the Changes fly-out remains stuck open after you commit pending changes.
               </p>
               <p>
                  <strong>Workarounds</strong>: Hover or click away. Then hover or click back to reopen the fly-out.
               </p>
               <p>
                  <strong>Fix</strong>: In LogStream 3.0.1.
               </p>
               <hr />
               <h3>2021-05-18 - 3.0.0 - Packs &gt; Export in "Merge" mode omits schemas and custom Functions</h3>
               <p>
                  <strong>Problem</strong>: <a url="packs" anchor="#export" href="https://docs.cribl.io/stream/packs#export" target="_blank">Exporting a Pack</a> with the export mode set to <code>Merge</code> omits schemas and custom Functions configured within the Pack's <strong>Knowledge &gt; Schemas</strong>.
               </p>
               <p>
                  <strong>Workarounds</strong>: 1. Change the export mode to <code>Mergesafe</code>, and export again. 2. If that doesn't preserve the schema and Functions, revert to <code>Merge</code> export mode; install the resulting Pack onto its target(s); and then manually copy/paste the schema(s) and Functions from the source Pack's UI to the target Pack's UI.
               </p>
               <p>
                  <strong>Fix</strong>: In LogStream 3.0.1.
               </p>
               <p />
               <hr />
               <h3>2021-05-17 - v.3.0.0-3.2.0 - Can't Enable KMS on WorkerGroup after installing license</h3>
               <p>
                  <strong>Problem</strong>: Enabling HashiCorp Vault or AWSKMS on a WorkerGroup, after installing a LogStream license on the same Group, fails with a spurious <code>External KMS is prohibited by the current license</code> error message.
               </p>
               <p>
                  <strong>Workaround</strong>: On the Leader, navigate to <strong>Settings</strong>&gt; <strong>WorkerProcesses</strong>. Restart the affected WorkerGroup's <code>CONFIG_HELPER</code> process. Thenreturn to that WorkerGroup's <strong>Security</strong>&gt; <strong>KMS</strong> Settings, re-enter the same KMS configuration, and save.
               </p>
               <hr />
               <h3>2021-05-10 - 2.4.5 - Elasticsearch Destination, with Auto version discovery, doesn't send Authorization header</h3>
               <p>
                  <strong>Problem</strong>: When the Elasticsearch Destination has Basic Authentication enabled, and its <strong>Elasticversion</strong> field specifies <code>Auto</code> version discovery, LogStream fails to send the configured username and password credentials along with its API initial request. Elasticsearch responds with an HTTP 401 error.
               </p>
               <p>
                  <strong>Workaround</strong>: Explicitly set the <strong>Elasticversion</strong> to either <code>7.x</code> or <code>6.x</code> (depending on your Elasticsearch cluster's version); then stop and restart LogStream to pick up this configuration change.
               </p>
               <p>
                  <strong>Fix</strong>: In LogStream 3.1.0.
               </p>
               <p />
               <p />
               <hr />
               <h3>2021-05-04 - 2.4.5 - Office 365 Message Trace Source skips events</h3>
               <p>
                  <strong>Problem</strong>: The <a url="event-breakers" href="https://docs.cribl.io/stream/event-breakers" target="_blank">Event Breaker</a> Rule provided for the <a product="stream" href="https://docs.cribl.io/stream/sources-office365-msg-trace" target="_blank">Office 365 Message Trace</a> Source mistakenly presets the <strong>Defaulttimezone</strong> to <code>ETC/GMT-0</code>. This setting causes LogStream to discover events but not collect them.
               </p>
               <p>
                  <strong>Workaround</strong>: Reset the Rule's <strong>Defaulttimezone</strong> to <code>UTC</code>, then click <strong>OK</strong> and resave the Ruleset.
               </p>
               <p>
                  <strong>Fix</strong>: In 3.0.2.
               </p>
               <p />
               <hr />
               <h3>2021-05-03 - v.2.4.4-3.01 - Rollup Function suppresses <code>sourcetype</code> metrics</h3>
               <p>
                  <strong>Problem</strong>: <code>sourcetype</code> metrics can be suppressed when the CriblInternal &gt; CriblMetrics Source is enabled and the <code>cribl_metrics_rollup</code> pre-processing Pipeline is attached to a Source.
               </p>
               <p>
                  <strong>Workarounds</strong>: Disabling the pre-processing pipeline restores <code>sourcetype</code> and any other missing data. However, without the rollup, a much higher data volume will be sent to the indexing tier.
               </p>
               <p>
                  <strong>Fix</strong>: In LogStream 3.0.2.
               </p>
               <hr />
               <h3>2021-04-20 - v.2.4.3-2.4.5 - Orphaned S3 staging directories</h3>
               <p>
                  <strong>Problem</strong>: Using the S3 Destination, defining a partitioning expression with high cardinality can proliferate a large number (up to millions) of empty directories. This is because LogStream cleans up staged files, but not staging directories.
               </p>
               <p>
                  <strong>Workaround</strong>: Programmatically or manually delete stale staging directories (e.g., those older than 30 days).
               </p>
               <p>
                  <strong>Fix</strong>: In LogStream 3.0.2.
               </p>
               <hr />
               <h3>2021-04-12 - 2.4.4 - Splunk Sources do not support multiple-metric events</h3>
               <p>
                  <strong>Problem</strong>: LogStream's Splunk Sources do not support multiple-measurement metric data points. (LogStream's Splunk LoadBalanced Destination does.)
               </p>
               <p>
                  <strong>Fix</strong>: In LogStream 3.0.1.
               </p>
               <hr />
               <h3>2021-04-07 - v.2.4.2-2.4.5 - Google Cloud Storage Destination fails to upload files &gt; 5 MB</h3>
               <p>
                  <strong>Problem</strong>: The Google Cloud Storage Destination might fail to put objects into GCS buckets. Thishappens with files larger than 5 MB, and causes the Google Cloud API to report a vague <code>Invalidargument</code> error.
               </p>
               <p>
                  <strong>Workaround</strong>: Set the <strong>Max file size (MB)</strong> to 5 MB. Also, reduce the <strong>Max file open time (sec)</strong> limit from its default <code>300</code> (5minutes) to a shorter interval, to prevent files from growing to the 5MB threshold. (Tune this limit based on your observed rate of traffic flow through the Destination.)
               </p>
               <p>
                  <strong>Fix</strong>: In LogStream 3.0.0.
               </p>
               <hr />
               <h3>2021-03-31 - v.2.4.4 - Local login option visible even when disabled</h3>
               <p>
                  <strong>Problem</strong>: The <strong>Log in with local user</strong> option is displayed to users even when you have disabled <strong>Settings &gt; Authentication &gt; Allowlocal auth</strong> for an OpenIDConnect identity provider.
               </p>
               <p>
                  <strong>Workaround</strong>: Advise users to ignore this button. Although visible, it will not function.
               </p>
               <p>
                  <strong>Fix</strong>: In LogStream 3.0.0.
               </p>
               <hr />
               <h3>2021-03-31 - v.2.4.0-2.4.4 - Splunk TCP and LB Destinations' Workers trigger OOM errors and restart</h3>
               <p>
                  <strong>Problem</strong>: With a Splunk TCP or Splunk Load Balanced Destination created after upgrading to LogStream 2.4.x, Workers' memory consumption may grow without bound, leading to out-of-memory errors. The API Process will restart the Workers, but there might be temporary outages.
               </p>
               <p>
                  <strong>Workaround</strong>: Toggle the Destination's <strong>AdvancedSettings&gt; Minimizein-flight data loss</strong> slider to <code>No</code>. This will preserve Processes killed by OOM conditions.
               </p>
               <p>
                  <strong>Fix</strong>: In LogStream 2.4.5.
               </p>
               <hr />
               <h3>2021-03-31 - v.2.4.4 - OpenID Connect authentication always shows local-auth fallback</h3>
               <p>
                  <strong>Problem</strong>: Even if OpenID Connect external authentication is <a product="stream" href="https://docs.cribl.io/stream/authentication#sso" target="_blank">configured</a> to disable <strong>Allowlocal auth</strong>, LogStream's login page displays a <strong>Login with local user</strong> button.
               </p>
               <p>
                  <strong>Workaround</strong>: Do not click that button.
               </p>
               <p>
                  <strong>Fix</strong>: In LogStream 3.0.0.
               </p>
               <hr />
               <h3>2021-03-31 - v.2.4.4 - Authentication options mistakenly display CriblCloud</h3>
               <p>
                  <strong>Problem</strong>: The <strong>Settings &gt; Authentication &gt; Type</strong> drop-down offers a <code>CriblCloud</code> option, which is not currently functional. Attempting to configure and save this option could lock the <code>admin</code> user out of LogStream.
               </p>
               <p>
                  <strong>Workaround</strong>: Do not select, configure, or save that option.
               </p>
               <p>
                  <strong>Fix</strong>: In LogStream 2.4.5.
               </p>
               <hr />
               <h3>2021-03-30 - v.2.4.4 - Can't disable some Sources from within their config modals</h3>
               <p>
                  <strong>Problem</strong>: In configuration modals for the AzureBlob Storage and Office365 Message Trace Sources, the <strong>Enabled</strong> slider cannot be toggled off, and its tooltip doesn't appear.
               </p>
               <p>
                  <strong>Workaround</strong>: Disable your configured Source (where required) from the <strong>ManageBlobStorage Sources</strong> or the <strong>ManageMessageTrace Sources</strong> page.
               </p>
               <p>
                  <strong>Fix</strong>: In LogStream 2.4.5.
               </p>
               <hr />
               <h3>2021-03-29 - v.2.4.x - SpaceOut Destination is broken</h3>
               <p>
                  <strong>Problem</strong>: Within the SpaceOut game, you cannot shoot, and your player is immortal.
               </p>
               <p>
                  <strong>Workaround</strong>: There are other video games. After we defeat COVID, you'll even be able to buy a PS5.
               </p>
               <p>
                  <strong>Fix</strong>: Restored in LogStream 2.4.5.
               </p>
               <hr />
               <h3>2021-03-24 - v.2.4.x - Cribl App for Splunk blocks admin password changes, configuration changes, and Splunk-based authentication</h3>
               <p>
                  <strong>Problem</strong>: Attempting to change the admin password via the UI triggers a 403/Forbidden message. You can reset the password by <a product="stream" href="https://docs.cribl.io/stream/authentication#manual-password-replacement" target="_blank">editing <code>users.json</code>
                  </a>, but can't save configuration changes to Settings, Pipelines, etc., because RBAC Roles are not properly applied.
               </p>
               <p>
                  <strong>Workaround</strong>: Using a <a href="https://cribl.io/download/logstream-past-releases/" target="_blank" rel="noopener noreferrer">2.3.x version</a> of the App enables <strong>local</strong> authentication and enables changes to Cribl/LogStream passwords and configuration/settings. 
               </p>
               <p>
                  <strong>Fix</strong>: In LogStream 2.4.4.
               </p>
               <hr />
               <h3>2021-03-22 - v.1.7 through 2.4.3 - Azure Event Hubs Destination: Compression must be manually disabled</h3>
               <p>
                  <strong>Problem</strong>: LogStream's <a url="destinations-azure-event-hubs" href="https://docs.cribl.io/stream/destinations-azure-event-hubs" target="_blank">Azure Event Hubs</a> Destination provides a <strong>Compression</strong> option that defaults to <code>Gzip</code>. However, compressed Kafka messages are not yet supported on Azure Event Hubs.
               </p>
               <p>
                  <strong>Workaround</strong>: Manually reset <strong>Compression</strong> to <code>None</code>, then resave Azure Event Hubs Destinations.
               </p>
               <p>
                  <strong>Fix</strong>: In LogStream 2.4.4.
               </p>
               <hr />
               <h3>2021-03-17 - v.2.4.2, 2.4.3 - Parser Function &gt; List of Fields copy/paste fails</h3>
               <p>
                  <strong>Problem</strong>: When copying/pasting <strong>Listof Fields</strong> contents between Parser Functions via the Copy button, the paste operation inserts unintended metadata instead of the original field references.
               </p>
               <p>
                  <strong>Workaround</strong>: Manually re-enter the second Parser Function's <strong>Listof Fields</strong>.
               </p>
               <p>
                  <strong>Fix</strong>: In LogStream 2.4.4.
               </p>
               <hr />
               <h3>2021-03-13 - v.2.4.3 - UI can't find valid TLS .key files, blocking Master restarts and Worker reconfiguration</h3>
               <p>
                  <strong>Problem</strong>: After upgrading to v.2.4.3, the UI fails to recognize valid TLS <code>.key</code> files, displaying spurious error messages of the form:
                  "File does not exist: <code>$CRIBL_HOME/local/cribl/auth/certs/&lt;keyname&gt;key</code>."
                  An affected Master will not restart. Affected Workers will restart, but will not apply changes made through the UI.
               </p>
               <p>
                  <strong>Workaround</strong>: Ideally, specify an absolute path to each key file, rather than relying on environment variables. If you're locked out of the UI, you'll need to manually edit the referenced paths within these configuration files in LogStream subdirectories: <code>local/cribl/cribl.yml</code> (General &gt; APIServer TLS settings) and/or <code>local/_system/instance.yml</code> (Distributed &gt; TLS settings). Contact Cribl Support if you need assistance. Amore drastic workaround is to disable TLS for the affected connections.
               </p>
               <p>
                  <strong>Fix</strong>: In LogStream 2.4.4.
               </p>
               <hr />
               <h3>2021-03-12 - v.2.4.2 - Redis Function with specific username can't authenticate against Redis 6.x ACLs</h3>
               <p>
                  <strong>Problem</strong>: The <a url="redis-function" href="https://docs.cribl.io/stream/redis-function" target="_blank">Redis</a> Function, when used with a specific username and Redis 6.x's <a href="https://redis.io/topics/acl" target="_blank" rel="noopener noreferrer">Access Control List</a> feature, fails due to authentication problems.
               </p>
               <p>
                  <strong>Workaround</strong>: In the Function's <strong>RedisURL</strong> field, point to the Redis <code>default</code> account, either with a password (e.g.,<code>redis://default:Password1@192.168.1.20:6379</code>) or with no password (redis://192.168.1.20:6379). Donot specify a user other than <code>default</code>.
               </p>
               <p>
                  <strong>Fix</strong>: In LogStream 3.0.
               </p>
               <hr />
               <h3>2021-03-09 - v.2.4.3 - Splunk Destinations' in-app docs mismatch UI's current field order</h3>
               <p>
                  <strong>Problem</strong>: For the Splunk Single Instance and Splunk LoadBalanced Destinations, the in-app documentation omits the UI's <strong>AdvancedSettings</strong> section. Some fields are documented out-of-sequence, or are omitted.
               </p>
               <p>
                  <strong>Workaround</strong>: Refer to the UI's tooltips, to the corrected <a url="destinations-splunk" href="https://docs.cribl.io/stream/destinations-splunk" target="_blank">Splunk Single Instance</a> and <a url="destinations-splunk-lb" href="https://docs.cribl.io/stream/destinations-splunk-lb" target="_blank">Splunk Load Balanced</a> online docs, and/or to the corrected <a href="https://cdn.cribl.io/dl/2.4.3/cribl-docs-2.4.3-20210310054833.pdf" target="_blank" rel="noopener noreferrer">PDF</a>.
               </p>
               <p>
                  <strong>Fix</strong>: In LogStream 2.4.4.
               </p>
               <hr />
               <h3>2021-03-08 - v.2.4.3 - Enabling Git Collapse Actions breaks Commit &amp; Deploy</h3>
               <p>
                  <strong>Problem</strong>: After enabling <strong>Settings &gt; DistributedSettings &gt; GitSettings &gt; General &gt; CollapseActions</strong>, selecting <strong>Commit&amp;Deploy</strong> throws a 500 error.
               </p>
               <p>
                  <strong>Workaround</strong>: Disable the <strong>CollapseActions</strong> setting, then commit and deploy separately.
               </p>
               <p>
                  <strong>Fix</strong>: In LogStream 2.4.4.
               </p>
               <hr />
               <h3>2021-03-08 - v.2.4.3 - S3 Collector lacks options to reuse HTTP connections and allow-self signed certs</h3>
               <p>
                  <strong>Problem</strong>: As of v.2.4.3, LogStream's AWS-related Sources &amp; Destinations provide options to reuse HTTP connections, and to establish TLS connections to servers with self-signed certificates. However, the S3 Collector does not yet provide these options.
               </p>
               <p>
                  <strong>Fix</strong>: In LogStream 2.4.4.
               </p>
               <hr />
               <h3>2021-03-04 - v.2.4.2 - Esc key closes both EventBreaker Ruleset modals</h3>
               <p>
                  <strong>Problem</strong>: After adding a rule to a <strong>Knowledge &gt; EventBreaker Ruleset</strong>, pressing <code>Esc</code> closes the parent Ruleset modal along with the child Rule modal.
               </p>
               <p>
                  <strong>Workaround</strong>: Close the Rule modal by clicking either its <strong>Cancel</strong> button or its close box.
               </p>
               <p>
                  <strong>Fix</strong>: In LogStream 2.4.3.
               </p>
               <hr />
               <h3>2021-03-04 - v.2.4.2 - Aggregations Function in post-processing Pipeline addresses wrong Destination</h3>
               <p>
                  <strong>Problem</strong>: An Aggregations Function, when used in a post-processing Pipeline, sends data to LogStream's Default Destination rather than to the Pipeline's attached Destination.
               </p>
               <p>
                  <strong>Workaround</strong>: If applicable, use the Function in a processing or pre-processing Pipeline instead.
               </p>
               <p>
                  <strong>Fix</strong>: In LogStream 2.4.3.
               </p>
               <hr />
               <h3>2021-02-25 - v.2.4.2 - On Safari, Event Breaker shows no OUT events</h3>
               <p>
                  <strong>Problem</strong>: When viewing an Event Breaker's results on Safari, no events are displayed on the Preview pane's <strong>OUT</strong> tab.
               </p>
               <p>
                  <strong>Workaround</strong>: Use another supported browser.
               </p>
               <p>
                  <strong>Fix</strong>: In LogStream 2.4.3.
               </p>
               <hr />
               <h3>2021-02-22 - v.2.4.3 - Collection jobs UI errors</h3>
               <p>
                  <strong>Problem</strong>: Collection jobs are missing from the <strong>Monitoring &gt; Sources</strong> page, even though they are returned by metric queries. Also, the <strong>JobInspector &gt; Live</strong> modal displays an empty, unintended <strong>Configure</strong> tab.
               </p>
               <p>
                  <strong>Workaround</strong>: Use the Job Inspector to access collection results. Ignore the <strong>Configure</strong>tab.
               </p>
               <p>
                  <strong>Fix</strong>: In LogStream 2.4.4.
               </p>
               <hr />
               <h3>2021-02-19 - v.2.4.2 - Upon upgrade, Git remote repo setting breaks, blocking Worker Groups</h3>
               <p>
                  <strong>Problem</strong>: If a Git remote repo was previously configured, upgrading to LogStream v.2.4.2 throws errors of this form upon startup: <code>Failed to initialize git repository. Config versioning will not be available...Invalid URL...</code>. The Master cannot commit or deploy to any Worker Group.
               </p>
               <p>
                  <strong>Workarounds</strong>: 1. Downgrade back to v.2.4.1 (or your previous working version). 2. Switch from Basic authentication to SSH authentication against the repo, to remove the username from requests. (Theapparent root cause is Basic/http auth using a valid URL and username, but missing a password.)
               </p>
               <p>
                  <strong>Fix</strong>: In LogStream 2.4.3.
               </p>
               <hr />
               <h3>2021-02-19 - v.2.4.0, 2.4.1, 2.4.2 - Splunk (S2S) Forwarder access control blocks upon upgrade to LogStream 2.4.x</h3>
               <p>
                  <strong>Problem</strong>: If Splunk indexers have forwarder tokens enabled, and worked with LogStream 2.3.x before, upgrading to LogStream 2.4.x causes data to stop flowing.
               </p>
               <p>
                  <strong>Workaround</strong>: If you encounter this problem, <a href="https://cribl.io/download/logstream-past-releases/" target="_blank" rel="noopener noreferrer">rolling back</a> to your previously installed LogStream version (such as v.2.3.4) resolves it.
               </p>
               <p>
                  <strong>Fix</strong>: In LogStream 2.4.3.
               </p>
               <hr />
               <h3>2021-02-10 - v.2.4.0, 2.4.1 - With Splunk HEC Source, JSON payloads containing embedded objects trigger high CPU usage</h3>
               <p>
                  <strong>Problem</strong>: Splunk HEC JSON payloads containing nested objects trigger high CPU usage, due to a flaw in JSON parsing. 
               </p>
               <p>
                  <strong>Workaround</strong>: If you encounter this problem, <a href="https://cribl.io/download/logstream-past-releases/" target="_blank" rel="noopener noreferrer">rolling back</a> to your previously installed LogStream version (such as v.2.3.4) resolves it.
               </p>
               <p>
                  <strong>Fix</strong>: In LogStream 2.4.2.
               </p>
               <hr />
               <h3>2021-01-30 - v.2.4.0 - Worker Nodes cannot connect to Master</h3>
               <p>
                  <strong>Problem</strong>: Worker Nodes cannot connect to the Master after the Master is upgraded to v.2.4.0.
               </p>
               <p>
                  <strong>Workaround</strong>: Disable compression on the Workers. You can do so through the Workers' UI at <strong>SystemSettings &gt; DistributedSettings &gt; MasterSettings &gt; Compression</strong>, or by commenting out this line in each Worker's <code>cribl.yml</code> config file: 
               </p>
               <div>
                  <div>
                     <pre>
                <code>
                  <span>
                    <span>compression: gzip</span>
                    <br/>
                  </span>
                </code>
              </pre>
                  </div>
               </div>
               <p>
                  <strong>Fix</strong>: In LogStream 2.4.1.
               </p>
               <hr />
               <h3>2021-01-25 - v.2.4.0 - S3collection stops working due to auth secret key issues.</h3>
               <p>
                  <strong>Problem</strong>: S3 collection stops after upgrade to 2.4.0 due to secret key re-encryption. 
               </p>
               <p>
                  <strong>Workaround</strong>: Re-configure S3, save and re-deploy.
               </p>
               <p>
                  <strong>Fix</strong>: In LogStream 2.4.1.
               </p>
               <hr />
               <h3>2021-01-14 - v.2.4.0 - Google Cloud Storage Destination Needs Extra Endpoint to Initialize</h3>
               <p>
                  <strong>Problem</strong>: The <a url="destinations-google-cloud-storage" href="https://docs.cribl.io/stream/destinations-google-cloud-storage" target="_blank">Google Cloud Storage</a> Destination fails to initialize, displaying an error of the form: <code>Bucket does not exist!</code>
               </p>
               <p>
                  <strong>Workaround</strong>: In the <code>outputs.yml</code> file, under your <code>cribl-gcp-bucket</code> key endpoint, add: <code>https://storage.googleapis.com</code>. (in a single-instance deployment, locate this file at <code>$CRIBL_HOME/local/cribl/outputs.yml</code>. In a distributed deployment, locate it at <code>$CRIBL_HOME/groups/&lt;group name&gt;/local/cribl/outputs.yml</code>.)
               </p>
               <p>
                  <strong>Fix</strong>: In LogStream 2.4.1.
               </p>
               <hr />
               <h3>2021-01-14 - v.2.4.0 - Worker Groups' Settings &gt; Access Management Is Absent from UI</h3>
               <p>
                  <strong>Problem</strong>: In this release, the <strong>WorkerGroups &gt; &lt;group-name&gt; &gt; SystemSettings</strong> UI did not display the expected <strong>AccessManagement</strong>, <strong>Authentication</strong>, and <strong>LocalUsers</strong> sections.
               </p>
               <p>
                  <strong>Workaround</strong>: <a product="stream" href="https://docs.cribl.io/stream/authentication#local-authentication" target="_blank">Manually edit</a> the <code>users.json</code> file.
               </p>
               <p>
                  <strong>Fix</strong>: In LogStream 2.4.1.
               </p>
               <hr />
               <h3>2021-01-13 - v.2.4.0 - Route Filters Aren't Copied to Capture Modal</h3>
               <p>
                  <strong>Problem</strong>: On the <strong>Routes</strong> page, selecting <strong>CaptureNew</strong> in the right pane does not copy custom <strong>Filter</strong> expressions to the resulting <strong>Capture Sample Data</strong> modal. Thatmodal's <strong>FilterExpression</strong> field always defaults to <code>true</code>.
               </p>
               <p>
                  <strong>Workarounds</strong>: 1. Bypass the <strong>CaptureNew</strong> button. Instead, from the Route's own •••(Options) menu, select <strong>Capture</strong>. This initiates a capture with the <strong>FilterExpression</strong> correctly populated. 2.Copy/paste the expression into the <strong>Capture Sample Data</strong> modal's <strong>FilterExpression</strong> field. Or,if the expression is displayed in that field's history drop-down, retrieve it.
               </p>
               <p>
                  <strong>Fix</strong>: In LogStream 2.4.1.
               </p>
               <hr />
               <h3>2021-01-13 - v.2.4.0 - Destinations' Documentation Doesn't Render from UI</h3>
               <p>
                  <strong>Problem</strong>: Clicking the <strong>Help</strong>link in a Destination's configuration modal displays the error message: "Unableto load docs. Please check LogStream's online documentation instead."
               </p>
               <p>
                  <strong>Workarounds</strong>: 1. Go directly to the online Destinations docs, starting <a url="destinations" href="https://docs.cribl.io/stream/destinations" target="_blank">here</a>. 2.Follow the UI link to the docs landing page, click through to open or download the current PDF, and scroll to its Destinations section.
               </p>
               <p>
                  <strong>Fix</strong>: In LogStream 2.4.1.
               </p>
               <hr />
               <h3>2021-01-13 - v.2.4.0 - <code>Esc</code> Key Doesn't Consistently Close Modals</h3>
               <p>
                  <strong>Problem</strong>: Pressing <code>Esc</code> with focus on a modal's drop-down or slider doesn't close the modal as expected. (Pressing <code>Esc</code> with focus on a free-text field, combo box, or nothing does close the modal - displaying a confirmation dialog first, if you have unsaved changes.)
               </p>
               <p>
                  <strong>Workarounds</strong>: Click the <strong>X</strong> close box at upper right, or click <strong>Cancel</strong> at lower right.
               </p>
               <p>
                  <strong>Fix</strong>: In LogStream 2.4.1.
               </p>
               <hr />
               <h3>2020-12-17 - v.2.3.0+ - Free-License Expiration Notice, Blocked Inputs</h3>
               <p>
                  <strong>Problem</strong>: LogStream reports an expired Free license, and blocks inputs, even though Free licenses in v.2.3.0 do not expire. 
               </p>
               <p>
                  <strong>Workaround</strong>: This is caused by time-limited Free license key originally entered in a LogStream version prior to 2.3.0. Go to <strong>Settings&gt; Licensing</strong>, click to select and expand your expired Free license, and click <strong>Deletelicense</strong>. LogStream will recognize the new, permanent Free license, and will restore throughput.
               </p>
               <p>
                  <strong>Fix</strong>: In LogStream 2.4.1.
               </p>
               <hr />
               <h3>2020-11-14 - v.2.3.3 - Null Fields Redacted in Preview, but Still Forwarded</h3>
               <p>
                  <strong>Problem</strong>: Where event fields have null values, LogStream (by default) displays them as struck-out in the right Preview pane. The preview is misleading, because the events are still sent to the output. 
               </p>
               <p>
                  <strong>Workaround</strong>: If you do want to prevent fields with null values from reaching the output, use an <a url="eval-function" href="https://docs.cribl.io/stream/eval-function" target="_blank">Eval</a> Function, with an appropriate Filter expression, to remove them.
               </p>
               <p>
                  <strong>Fix</strong>: Preview corrected in LogStream 2.3.4.
               </p>
               <hr />
               <h3>2020-10-27 - v.2.3.2 - Cannot Name or Save New Event Breaker Rule</h3>
               <p>
                  <strong>Problem</strong>: After clicking <strong>AddRule</strong> in a new or existing EventBreaker Ruleset, the <strong>EventBreakerRule</strong> modal's <strong>RuleName</strong> field is disabled. Because <strong>RuleName</strong> is mandatory field, this also disables saving the Rule via the <strong>OK</strong> button.
               </p>
               <p>
                  <strong>Fix</strong>: In LogStream 2.3.3.
               </p>
               <hr />
               <h3>2020-10-12 - v.2.3.1 - Deleting One Function Deletes Others in Same Group</h3>
               <p>
                  <strong>Problem</strong>: After inserting a new Function into a group and saving the Pipeline, deleting the Function also deletes other Functions lower down in the same group.
               </p>
               <p>
                  <strong>Fix</strong>: In LogStream 2.3.2.
               </p>
               <p>
                  <strong>Workaround</strong>: Move the target Function out of the group, resave the Pipeline, and only then delete the Function.
               </p>
               <hr />
               <h3>2020-09-27 - v.2.3.1 - Enabling Boot Start as Different User Fails</h3>
               <p>
                  <strong>Problem</strong>: When a root user tries to enable <a product="stream" href="https://docs.cribl.io/stream/deploy-single-instance#enabling-start-on-boot" target="_blank">boot-start</a> as a different user (e.g., using <code>/opt/cribl/bin/cribl boot-start enable -u &lt;some-username&gt;</code>), they receive an error of this form:
               </p>
               <div>
                  <div>
                     <pre>
                <code>
error: found user=0 as owner for path=/opt/cribl, expected uid=NaN. 
Please make sure CRIBL_HOME and its contents are owned by the uid=NaN by running: 
[sudo] chown -R NaN:[$group] /opt/cribl 
                </code>
              </pre>
                  </div>
               </div>
               <p>
                  <strong>Fix</strong>: In LogStream 2.3.2.
               </p>
               <p>
                  <strong>Workaround</strong>: Install LogStream 2.2.3 (which you can download <a href="https://cdn.cribl.io/dl/2.2.3/cribl-2.2.3-90f21f14-linux-x64.tgz" target="_blank" rel="noopener noreferrer">here</a>), then upgrade to 2.3.1.
               </p>
               <hr />
               <h3>2020-09-17 - v.2.3.0 - Worker Groups menu tab hidden after upgrade to LogStream 2.3.0</h3>
               <p>
                  <strong>Problem</strong>: Upon upgrading an earlier, licensed LogStream installation to v.2.3.0, the <strong>WorkerGroups</strong> tab might be absent from the Master Node's top menu.
               </p>
               <p>
                  <strong>Fix</strong>: In LogStream 2.3.1.
               </p>
               <p>
                  <strong>Workaround</strong>: Click the <strong>Home&gt; WorkerGroups</strong> tile to access Worker Groups.
               </p>
               <hr />
               <h3>2020-09-17 - v.2.3.0 - Cannot Start LogStream 2.3.0 on RHEL 6, RHEL 7</h3>
               <p>
                  <strong>Problem</strong>: Upon upgrading to v.2.3.0, LogStream might fail to start on RHEL 6 or 7, with an error message of the following form. This occurs when the user running LogStream doesn't match the LogStream binary's owner. LogStream 2.3.0 applies a restrictive permissions check using <code>id -un &lt;uid&gt;</code>, which does not work with the version of <code>id</code> that ships with these RHEL releases.
               </p>
               <div>
                  <div>
                     <pre>
                <code>
id: 0: No such user
ERROR: Cannot run command because user=root with uid=0 does not own executable 
                </code>
              </pre>
                  </div>
               </div>
               <p>
                  <strong>Fix</strong>: In LogStream 2.3.1.
               </p>
               <p>
                  <strong>Workaround</strong>: Update your RHEL environment's <code>id</code> version, if possible.
               </p>
               <hr />
               <h3>2020-09-17 - v.2.3.0 - Cannot Start LogStream 2.3.0 with OpenId Connect</h3>
               <p>
                  <strong>Problem</strong>: Upon upgrading an earlier LogStream installation to v.2.3.0, OIDC users might be unable to restart the LogStream server.
               </p>
               <p>
                  <strong>Fix</strong>: In LogStream 2.3.1.
               </p>
               <p>
                  <strong>Workaround</strong>: Edit <code>$CRIBL_HOME/default/cribl/cribl.yml</code> to add the following lines to its the <code>auth</code> section:
               </p>
               <div>
                  <div>
                     <pre>
                <code>
filter_type: email_whitelist
scope: openid profile email
                </code>
              </pre>
                  </div>
               </div>
               <hr />
               <h3>2020-06-11 - v.2.1.x - Can't switch from Worker to Master Mode</h3>
               <p>
                  <strong>Problem</strong>: In a Distributed deployment, attempting to switch Distributed Settings from Worker to Master Mode blocks with a spurious "Git not available...Please install and try again" error message.
               </p>
               <p>
                  <strong>Fix</strong>: In LogStream 2.3.0.
               </p>
               <p>
                  <strong>Workaround</strong>: To initialize <code>git</code>, switch first from Worker to Single mode, and then from Single to Master mode.
               </p>
               <hr />
               <h3>2020-05-19 - v.2.1.x - Login page blocks</h3>
               <p>
                  <strong>Problem</strong>: Entering valid credentials on the login page (e.g., <code>http://localhost:9000/login</code>) yields only a spinner.
               </p>
               <p>
                  <strong>Fix</strong>: In LogStream 2.3.0.
               </p>
               <p>
                  <strong>Workaround</strong>: Trim <code>/login</code> from the URL.
               </p>
               <hr />
               <h3>2020-02-22 - v.2.1.x - Deleting resources in <code>default/</code>
               </h3>
               <p>
                  <strong>Problem</strong>: In a Distributed deployment, deleting resources in <code>default/</code> causes them to reappear on restart. 
               </p>
               <p>
                  <strong>Workaround/Fix</strong>: In progress. 
               </p>
               <hr />
               <h3>2019-10-22 - v. 2.0 - In-product upgrade issue on v2.0</h3>
               <p>
                  <strong>Problem</strong>: Using in-product upgrade feature in v.1.7 (or earlier) fails to upgrade to v2.0, due to package-name convention change. 
               </p>
               <p>
                  <strong>Workaround/Fix</strong>: Download the new version and upgrade per steps laid out <a product="stream" href="https://docs.cribl.io/stream/upgrading" target="_blank">here</a>.
               </p>
               <hr />
               <h3>2019-08-27 - v.1.7 - In-product upgrade issue on v1.7</h3>
               <p>
                  <strong>Problem</strong>: Using in-product upgrade feature in v1.6 (or earlier) fails to upgrade to v1.7 due to package name convention change. 
               </p>
               <p>
                  <strong>Workaround/Fix</strong>: Download the new package and upgrade per steps laid out <a product="stream" href="https://docs.cribl.io/stream/upgrading" target="_blank">here</a>.
               </p>
               <hr />
               <h3>2019-03-21 - v.1.4 - S3 stagePath issue on upgrade to v.1.4+</h3>
               <p>
                  <strong>Problem</strong>: When upgrading from v1.2 with a S3 output configured, <code>stagePath</code> was allowed to be undefined. In v.1.4+, <code>stagePath</code> is a required field. This might causing schema violations when upgrading older configs.
               </p>
               <p>
                  <strong>Workaround/Fix</strong>: Reconfigure the output with a valid <code>stagePath</code> filesystem path.
               </p>
            </div>
         </html>
      </panel>
   </row>
</dashboard>